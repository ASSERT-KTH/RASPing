# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15u7yGrz_dAakFxkxV7IIVZ8Dr7PsGWbT
"""

import random
import numpy as np
import graphviz
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import torch

from tracr.rasp import rasp

# List of the available operations, the programs are being generated with. Expand to increase program complexity


ops = ["select", "select_width", "aggregate", "map", "sequence_map"]

# weights for random selection of operations
weights = [
    70,  # select
    16,  # select_width
    28,  # aggregate
    14,  # map
    19,  # sequence_map
]


lambda1s = [
    "lambda x: x+2",  # double increment
    "lambda x: 2*x",  # Double
    "lambda x: x/2",  # Half
    "lambda x: abs(x)",  # Absolute value
    "lambda x: -x",  # Negation
    "lambda x: x % 2",  # Modulo 2 (remainder when divided by 2)
    "lambda x: 1/x if x != 0 else 0",  # Inverse, with divide-by-zero handling
    "lambda x: x**0.5",  # Square root
    "lambda x: x if x > 0 else 0",  # ReLU (Rectified Linear Unit)
    "lambda x: 1 if x > 0 else 0",  # Step function
]

lambda2s = [
    "lambda x, y: x + y",  # Addition
    "lambda x, y: x - y",  # Subtraction
    "lambda x, y: x * y",  # Multiplication (probability of this being chosen should be massivley reduced)
    "lambda x, y: x * (y + 1)",  # Multiplication with increment (probability of this being chosen should be massivley reduced)
    "lambda x, y: x / y if y != 0 else 0",  # Division, with handling for divide-by-zero
    "lambda x, y: x ** (1/y)",  # Root
    "lambda x, y: (x + y) / 2",  # Average
]
lambda3s = [
    "lambda x, y: x == y",
    "lambda x, y: x >= y",
    "lambda x, y: x > y",
    "lambda x, y: x <= y",
    "lambda x, y: x < y",
    "lambda x, y: x != y",
    "lambda x, y: True",
]

special_variables = {2: lambda1s, 3: lambda2s, 4: lambda3s}


def select(a, b, c):
    return rasp.Select(a, b, c)


def aggregate(a, b):
    return rasp.Aggregate(b, a)


def select_width(a):
    return rasp.SelectorWidth(a)


def sequence_map(a, b, c):
    return rasp.SequenceMap(a, b, c)


"""
def map(a, b):
    return rasp.Map(a, b)
"""


def make_length():
    all_true_selector = rasp.Select(rasp.tokens, rasp.tokens, rasp.Comparison.TRUE)
    return rasp.SelectorWidth(all_true_selector)


# dict that maps operations to input types
in_datatype_lookup = {
    "select": [0, 0, 4],
    "aggregate": [0, 1],
    "select_width": [1],
    "map": [2, 0],
    "sequence_map": [3, 0, 0],
}

# dict that maps operations to output types
out_datatype_lookup = {
    "var": 0,
    "select": 1,
    "select_width": 0,
    "aggregate": 0,
    "map": 0,
    "sequence_map": 0,
}

# dict that maps operations to operation labels
int_to_type = {
    0: "var",
    1: "select",
    2: "select_width",
    3: "aggregate",
    4: "map",
    5: "sequence_map",
}

type_to_int = {
    "var": 0,
    "select": 1,
    "select_width": 2,
    "aggregate": 3,
    "map": 4,
    "sequence_map": 5,
}


# Generates computational tree of a rasp program. phase1 dictates the number of steps in which the computational tree expands, before it starts to converge
def random_rasp(phase1=7):
    nodes = [
        [0, "var", []],
        [1, "var", []],
        [2, "var", []],
    ]

    available_inputs = [
        nodes[0],
        nodes[1],
        nodes[2],
    ]

    phase = 0
    nodes_made = 0
    while len(available_inputs) > 1:
        op = random.choice(ops[:3])
        valid_found = False
        tested = {op: False for op in ops[:3]}
        print(op)
        while not valid_found:
            valid = True
            for i in in_datatype_lookup[op]:
                input_possible = False
                for j in available_inputs:
                    if out_datatype_lookup[j[1]] == i:
                        # print("op:",j[1],"out_datatype_lookup:",out_datatype_lookup[j[1]])
                        # print(f"possible inputs for {op}:", in_datatype_lookup[op])
                        input_possible = True
                valid = valid and input_possible
            valid_found = valid
            if not valid:
                tested[op] = True
                tested_all = True
                for key in tested.keys():
                    if not tested[key]:
                        tested_all = False
                if tested_all:
                    return nodes
                    return False

                op = random.choice(ops[:3])

        id = len(nodes)
        inputs = []
        input_nodes = []
        for i in range(len(in_datatype_lookup[op])):
            found = False
            while not found:
                inp = random.choice(available_inputs)
                if out_datatype_lookup[inp[1]] == in_datatype_lookup[op][i]:
                    found = True
                    inputs.append(inp[0])
                    input_nodes.append(inp)
        if phase == 1:
            for inp in input_nodes:
                if inp in available_inputs:
                    available_inputs.remove(inp)
        new_node = [id, op, inputs]
        nodes.append(new_node)
        available_inputs.append(new_node)

        nodes_made += 1
        if nodes_made > phase1:
            phase = 1
    if out_datatype_lookup[nodes[-1][1]] == 1:
        nodes.append([len(nodes), "aggregate", [nodes[-1][2][0], len(nodes) - 1]])
    return nodes


# uses the random_rasp function to find a graph with suitable parameters (max length) in a las vegas search
def generate_rasp_comp_tree(max_len=31, buildup_phase=5, full_complexity=False):
    sub_max_len = False
    r_prog = False
    len_tries = 0

    while not sub_max_len:
        val_tries = 0
        if len_tries > 20:
            return generate_rasp_comp_tree(
                max_len=max_len,
                buildup_phase=buildup_phase,
                full_complexity=full_complexity,
            )
        while not r_prog:
            val_tries += 1
            # print(val_tries)
            if full_complexity:
                r_prog = random_rasp_full(
                    phase1=buildup_phase, operations=ops, sv=special_variables
                )
            else:
                s = {2: lambda1s, 3: lambda2s, 4: lambda3s[:1]}
                r_prog = random_rasp_full(
                    phase1=buildup_phase, operations=ops[:3], sv=s
                )
            if len_tries > 20:
                return generate_rasp_comp_tree(
                    max_len=max_len,
                    buildup_phase=buildup_phase,
                    full_complexity=full_complexity,
                )
        if len(r_prog) <= max_len and not out_datatype_lookup[r_prog[-1][1]] == 1:
            for i in r_prog:
                sub_max_len = True
        # print("len:",len(r_prog),"out-type:", out_datatype_lookup[r_prog[-1][1]])
        len_tries += 1

    return r_prog


def visualize_tree(graph):
    dot = graphviz.Digraph(format="png")

    # Define the nodes and edges for the computational graph
    # Note: For simplicity, only a subset of nodes and edges are shown here
    # Full code representation would be very extensive
    nodes = []
    for i in graph:
        nodes.append(f"var{i[0]} {i[1]}")

    edges = []
    for i in graph:
        if i[1] != "var":
            for j in range(len(in_datatype_lookup[i[1]])):
                if i[2][j] != 31:
                    if in_datatype_lookup[i[1]][j] < 2:
                        edges.append(
                            (f"var{i[2][j]} {graph[i[2][j]][1]}", f"var{i[0]} {i[1]}")
                        )

    # Add the nodes to the graph
    for node in nodes:
        dot.node(node)

    # Add the edges to the graph
    for edge in edges:
        dot.edge(*edge)

    # Render and save the graph
    path = "/Users/hannes/Desktop/Transformer_Decompiler/appollo_research_project/comp_graph"
    dot.render(
        path, cleanup=True
    )  # Set cleanup=True to remove the dot source file after rendering

    path += ".png"
    img = mpimg.imread(path)

    # Display the image
    plt.imshow(img)
    plt.axis("off")  # Turn off axis numbers
    plt.show()


# takes in a string program and converts it to a computational graph (as produced by random rasp)
def program_to_graph(program_str):
    graph = []
    lines = program_str.strip().split("\n")
    for line in lines:
        parts = line.split(" = ")
        if len(parts) == 1:  # It's a 'var' declaration without assignment
            var_id = int(parts[0][3:])
            graph.append([var_id, "var", []])
        elif len(parts) != 2:
            raise SyntaxError("Invalid assignment statement.")

        var_id = int(parts[0][3:])
        op_and_args = parts[1].split("(")

        op = op_and_args[0]
        args = op_and_args[1]

        if args:
            arg_ids = [int(arg[3]) for arg in args.split(", ")[:2]]
        else:
            arg_ids = []

        graph.append([var_id, op, arg_ids])

    return graph


# Generates computational tree of a rasp program. phase1 dictates the number of steps in which the computational tree expands, before it starts to converge
def random_rasp_full(phase1=7, operations=ops, sv: dict = special_variables):
    ops = operations
    special_variables = sv

    nodes = [
        [0, "var", []],
        [1, "var", []],
        # [2, "var", []],
    ]

    available_inputs = [nodes[0], nodes[1]]  # , nodes[2],

    phase = 0
    nodes_made = 0
    while len(available_inputs) > 1:
        op = random.choices(ops, weights=weights[: len(ops)], k=1)[0]
        valid_found = False
        tested = {op: False for op in ops}
        while not valid_found:
            valid = True
            for i in in_datatype_lookup[op]:
                input_possible = False
                if i > 1:
                    input_possible = True
                else:
                    for j in available_inputs:
                        if out_datatype_lookup[j[1]] == i:
                            input_possible = True
                valid = valid and input_possible
            valid_found = valid
            if not valid:
                tested[op] = True
                tested_all = True
                for key in tested.keys():
                    if not tested[key]:
                        tested_all = False
                if tested_all:
                    return False
                op = random.choices(ops, weights=weights[: len(ops)], k=1)[0]

        id = len(nodes)
        inputs = []
        input_nodes = []
        for i in range(len(in_datatype_lookup[op])):
            if in_datatype_lookup[op][i] > 1:
                inputs.append(
                    np.random.randint(len(special_variables[in_datatype_lookup[op][i]]))
                )
            else:
                found = False
                while not found:
                    inp = random.choice(available_inputs)
                    if out_datatype_lookup[inp[1]] == in_datatype_lookup[op][i]:
                        found = True
                        inputs.append(inp[0])
                        input_nodes.append(inp)
        nodes_made += 1
        if nodes_made > phase1:
            phase = 1
        if phase == 1:
            for inp in input_nodes:
                if inp in available_inputs:
                    available_inputs.remove(inp)
        new_node = [id, op, inputs]
        nodes.append(new_node)
        available_inputs.append(new_node)

    if out_datatype_lookup[nodes[-1][1]] == 1:
        nodes.append([len(nodes), "aggregate", [nodes[-1][2][0], len(nodes) - 1]])
    return nodes


# takes in a computational graph in the form of a list of nodes, and produces a program in string form. "include_vars" dictates whether to include nodes of type "var" since they are sometimes padding and otherwise always the same
def graph_to_program(graph, include_vars=False):
    program_str = ""
    for node in graph:

        if node[1] == "var":
            if include_vars:
                program_str += f"var{node[0]}\n"
        elif node[1] == "invalid_func":
            program_str += "invalid_func"
        else:
            line = f"var{node[0]} = {node[1]}("
            for i in range(len(in_datatype_lookup[node[1]])):
                if in_datatype_lookup[node[1]][i] > 1:
                    try:
                        line += special_variables[in_datatype_lookup[node[1]][i]][
                            node[2][i]
                        ]
                    except:
                        line += "invalid lambda"
                    if i < len(in_datatype_lookup[node[1]]) - 1:
                        line += ", "
                else:
                    line += f"var{node[2][i]}"
                    if i < len(in_datatype_lookup[node[1]]) - 1:
                        line += ", "
            line += ")\n"
            program_str += line
    return program_str


# same as graph to program but features nested functions to reduce line count (and therefore might better readibility?)
def graph_to_program_short(graph, max_nested_calls=0):
    usage_count = {node[0]: 0 for node in graph}
    for node in graph:
        for inp in node[2]:
            usage_count[inp] = usage_count.get(inp, 0) + 1

    def generate_expr(var_id, graph, usage_count):
        node = graph[var_id]
        if node[1] == "var" or usage_count[var_id] > 1:
            return f"var{var_id}"
        inputs = ", ".join(generate_expr(i, graph, usage_count) for i in node[2])

        # If there are more than max_nested_calls nested function calls, create an intermediate variable
        if inputs.count("(") > max_nested_calls:
            return f"var{var_id}"
        return f"{node[1]}({inputs})"

    program_str = ""
    for i, node in enumerate(graph):
        if node[1] == "var":
            program_str += f"var{i}\n"
        else:
            expr = generate_expr(i, graph, usage_count)
            if expr.startswith("var"):  # It's an intermediate variable
                sub_expr = ", ".join(
                    generate_expr(inp, graph, usage_count) for inp in node[2]
                )
                program_str += f"var{i} = {node[1]}({sub_expr})\n"
            elif usage_count[i] > 1:
                program_str += f"var{i} = {expr}\n"

    return program_str


# Turns a graph into a vector of bits containing num_bits_for_type bits for the type of function and num_bits_for_label of the nodes that produce the input.
def vectorize_graph(
    graph, num_bits_for_type=2, num_bits_for_label=5, num_chunks_per_line=3
):

    # Calculate the length of binary description for each node (excluding the label)
    total_bits_per_node = num_bits_for_type + 2 * num_bits_for_label  # type, 2 inputs

    # Initialize the binary array
    binary_array = np.zeros((len(graph), total_bits_per_node), dtype=np.int8)

    for i, node in enumerate(graph):
        _, type_str, inputs = node  # Ignoring label
        inputs = inputs[: num_chunks_per_line - 1]
        type_int = type_to_int[type_str]

        # Fill in the type bits
        type_bits = [int(b) for b in format(type_int, f"0{num_bits_for_type}b")]
        binary_array[i, :num_bits_for_type] = type_bits

        # Fill in the input bits
        for j, inp in enumerate(inputs):
            input_bits = [int(b) for b in format(inp, f"0{num_bits_for_label}b")]
            start_idx = num_bits_for_type + j * num_bits_for_label
            end_idx = start_idx + num_bits_for_label
            binary_array[i, start_idx:end_idx] = input_bits

    return binary_array, num_bits_for_type, num_bits_for_label


# new program encoding scheme
def one_hot_encode(value, max_val):
    if value >= max_val:
        raise ValueError("Value should be less than max_val")

    one_hot = [0] * max_val
    one_hot[value] = 1
    return one_hot


def line_tokenisze_graph_ohe(
    graph,
    chunk_length=32,
    include_line_label=False,
    split_chunks=True,
    include_lambdas=True,
):
    out = []
    chunks_per_line = 3  # how many chunks in a line
    if include_lambdas:
        chunks_per_line += 1
    if include_line_label:
        chunks_per_line += 1
    for node in graph:
        line = []
        if include_line_label:
            line.append(node[0])
        line.append(type_to_int[node[1]])
        line += node[2]
        while len(line) < chunks_per_line:
            line.append(-1)
        line = line[:chunks_per_line]
        token = []
        # print(line)
        for i in line:
            if split_chunks:
                token.append(one_hot_encode(i, chunk_length))
            else:
                token += one_hot_encode(i, chunk_length)
        if split_chunks:
            out += token
        else:
            out.append(token)
    return out


# Turns a binary vector back into a graph so that it may be turned into a readable program
def devectorize_graph(binary_array, num_bits_for_type, num_bits_for_label):
    int_to_type = {
        0: "var",
        1: "select",
        2: "select_width",
        3: "aggregate",
        4: "map",
        5: "sequence_map",
    }

    # Calculate the length of binary description for each node (excluding the label)
    total_bits_per_node = num_bits_for_type + 2 * num_bits_for_label  # type, 2 inputs

    # Reshape the binary array
    binary_matrix = binary_array.reshape(-1, total_bits_per_node)

    graph = []
    for i, row in enumerate(binary_matrix):
        # Extract the type bits and convert to integer
        type_bits = row[:num_bits_for_type]
        type_int = int("".join(str(int(bit)) for bit in type_bits), 2)
        # Get the type string
        type_str = int_to_type.get(type_int, "invalid_func")
        # Node label is just the index i
        label = i

        # Extract the input bits and convert to integers
        inputs = []
        for j in range(2):
            start_idx = num_bits_for_type + j * num_bits_for_label
            end_idx = start_idx + num_bits_for_label
            input_bits = row[start_idx:end_idx]
            input_label = int("".join(str(int(bit)) for bit in input_bits), 2)
            if (
                input_label < label
            ):  # Assuming the graph is acyclic and nodes appear in topological order
                inputs.append(input_label)
        inputs.append(0)

        # Create the node and add it to the graph
        node = [label, type_str, inputs]
        graph.append(node)

    return graph


def detokenise_graph_ohe(ohe_array, label_included=False):
    int_to_type = {
        0: "var",
        1: "select",
        2: "select_width",
        3: "aggregate",
        4: "map",
        5: "sequence_map",
    }
    # [0, "var", [2,3,4]],
    graph = []
    for i in range(int(len(ohe_array) / 4)):
        node = []
        node.append(i)
        try:
            node.append(int_to_type[int(torch.argmax(torch.tensor(ohe_array[i * 4])))])
        except:
            node.append("var")
        inputs = []
        for j in range(1, 4):
            inputs.append(int(torch.argmax(torch.tensor(ohe_array[i * 4 + j]))))

        node.append(inputs)
        graph.append(node)
    return graph


s = {2: lambda1s, 3: lambda2s, 4: lambda3s[:1]}
r_prog2 = random_rasp_full(phase1=1, operations=ops, sv=s)
# tokens = vectorize_graph(r_prog2, num_bits_for_type = 5)[0].reshape(-1,5)
tokens = line_tokenisze_graph_ohe(r_prog2, include_line_label=False)
print(np.array(tokens).shape)
nodes = detokenise_graph_ohe(tokens)
visualize_tree(nodes)
print(graph_to_program(nodes))
