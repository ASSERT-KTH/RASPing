{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcasing different results when encoded vs. decoded\n",
    "\n",
    "This notebook showcases a problem where, for the same input, the encoded and decoded outputs are different. The problem happens after we train the compiled tranformer model.\n",
    "\n",
    "This is a minimal example to showcase the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading an example program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracr.compiler import lib\n",
    "from tracr.rasp import rasp\n",
    "from tracr.compiler import compiling\n",
    "\n",
    "tokens = {1,2,3,4,5,6}\n",
    "max_size = 5\n",
    "sort = lib.make_sort(rasp.tokens, rasp.tokens, max_seq_len=max_size, min_key=min(tokens))\n",
    "model = compiling.compile_rasp_to_model(sort, tokens, max_size, compiler_bos=\"BOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOS', 1, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply([\"BOS\", 4, 3, 5, 6, 1]).decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate some data to train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655\n",
      "(['BOS', np.int64(4), np.int64(5), np.int64(3), np.int64(5)], ['BOS', np.int64(3), np.int64(4), np.int64(5), np.int64(5)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "data = []\n",
    "dataset = set()\n",
    "data_size = 1000\n",
    "for i in range(data_size):\n",
    "    inputLength = np.random.randint(2, max_size+1)\n",
    "\n",
    "    inputSeq = []\n",
    "    outputSeq = []\n",
    "    for t in np.random.choice(list(tokens), inputLength):\n",
    "        inputSeq.append(t)\n",
    "        outputSeq.append(t)\n",
    "\n",
    "    inputSeq.insert(0,\"BOS\")\n",
    "    outputSeq.sort()\n",
    "    outputSeq.insert(0,\"BOS\")\n",
    "\n",
    "    if tuple(inputSeq) not in dataset:\n",
    "        dataset.add(tuple(inputSeq))\n",
    "        data.append((inputSeq, outputSeq))\n",
    "\n",
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 'BOS': 6, 'compiler_pad': 7}\n",
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5}\n",
      "(500, 6) (89, 6) (66, 6)\n",
      "(500, 6) (89, 6) (66, 6)\n",
      "[6 3 4 2 4 7]\n",
      "[0 2 3 4 4 0]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "inputEncoder = model.input_encoder\n",
    "outputEncoder = model.output_encoder\n",
    "\n",
    "print(inputEncoder.encoding_map)\n",
    "print(outputEncoder.encoding_map)\n",
    "\n",
    "# outputEncoder does not support pad tokens, so we use a filler token that is ignored by the loss function\n",
    "fillerToken = next(iter(outputEncoder.encoding_map))\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for inputSeq, outputSeq in data:\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(max_size+1):\n",
    "        if i < len(inputSeq):   #Assumes that input is same size as output\n",
    "            x.append(inputSeq[i])\n",
    "            y.append(outputSeq[i])\n",
    "        else:\n",
    "            x.append(\"compiler_pad\")\n",
    "            y.append(fillerToken)\n",
    "\n",
    "    y[0] = fillerToken\n",
    "\n",
    "    X.append(inputEncoder.encode(x))\n",
    "    Y.append(outputEncoder.encode(y))\n",
    "\n",
    "   \n",
    "X = jnp.array(X)\n",
    "Y = jnp.array(Y)\n",
    "\n",
    "split = int(X.shape[0] * 0.90)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_train, Y_test = Y[:split], Y[split:]\n",
    "split = int(X_train.shape[0] * 0.85)\n",
    "X_train, X_val = X_train[:split], X_train[split:]\n",
    "Y_train, Y_val = Y_train[:split], Y_train[split:]\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "\n",
    "print(X_train[0])\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from typing import NamedTuple\n",
    "import haiku as hk\n",
    "import optax\n",
    "\n",
    "class TrainingState(NamedTuple):\n",
    "    params: hk.Params\n",
    "    opt_state: optax.OptState\n",
    "    step: jax.Array\n",
    "\n",
    "def optimiser(lr) -> optax.GradientTransformation:\n",
    "    return optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        optax.adam(lr),\n",
    "    )\n",
    "\n",
    "def forward(x):\n",
    "    compiled_model = model.get_compiled_model()\n",
    "    compiled_model.use_unembed_argmax = False\n",
    "    return compiled_model(x, use_dropout=False)\n",
    "\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def loss_fn(x, y, padToken):\n",
    "    # Loss is the average negative log-likelihood per token (excluding the first token and padding tokens)\n",
    "    logits = forward(x).unembedded_output\n",
    "    log_probs = jax.nn.log_softmax(logits)\n",
    "    one_hot_targets = jax.nn.one_hot(y, logits.shape[-1])\n",
    "    log_likelihood = jnp.sum(one_hot_targets * log_probs, axis=-1)\n",
    "    # Mask the first token (BOS)\n",
    "    mask = jnp.ones_like(log_likelihood)\n",
    "    mask = mask.at[:, 0].set(0.0)\n",
    "    # Mask the padding tokens\n",
    "    padMask = jnp.where(x!=padToken, mask, 0.0)\n",
    "    # Return the average negative log-likelihood per token\n",
    "    return -jnp.mean(log_likelihood * padMask) / jnp.sum(padMask)\n",
    "\n",
    "@jax.jit\n",
    "def update(state: TrainingState, x, y, lr: float, padToken) -> TrainingState:\n",
    "    loss_and_grads_fn = jax.value_and_grad(loss_fn.apply)\n",
    "    loss, grads = loss_and_grads_fn(state.params, x, y, padToken)\n",
    "    updates, opt_state = optimiser(lr).update(grads, state.opt_state)\n",
    "    params = optax.apply_updates(state.params, updates)\n",
    "    metrics = {\"step\": state.step, \"loss\": loss}\n",
    "    return TrainingState(params, opt_state, step=state.step+1), metrics\n",
    "\n",
    "@jax.jit\n",
    "def init(initial_params: hk.Params, lr: float) -> TrainingState:\n",
    "    initial_opt_state = optimiser(lr).init(initial_params)\n",
    "    return TrainingState(\n",
    "        params=initial_params,\n",
    "        opt_state=initial_opt_state,\n",
    "        step=jnp.array(0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\00tho\\documents\\courses\\degreeproject\\rasping\\.venv\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\00tho\\documents\\courses\\degreeproject\\rasping\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomize starting weights\n",
    "PRNGSeq = hk.PRNGSequence(42)\n",
    "randomParams = jax.tree_util.tree_map(\n",
    "    lambda p: jax.random.normal(next(PRNGSeq), p.shape), model.params\n",
    ")\n",
    "model.params = randomParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:11<00:00, 14.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "padToken = model.input_encoder.encoding_map[\"compiler_pad\"]\n",
    "num_epochs = 1500\n",
    "batch_size = 256\n",
    "lr = 1e-4\n",
    "state = init(model.params, lr)\n",
    "\n",
    "for epoch in tqdm.trange(num_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        x = X_train[i:i + batch_size]\n",
    "        y = Y_train[i:i + batch_size]\n",
    "        state, metric = update(state, x, y, lr, padToken)\n",
    "        model.params = state.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we run the model with both encoded and decoded inputs/outputs to showcase the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 655/655 [00:45<00:00, 14.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy encoded: 0.004580152671755725\n",
      "Accuracy decoded: 0.0030534351145038168\n",
      "Different samples: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "forward_fn = hk.without_apply_rng(hk.transform(forward))\n",
    "\n",
    "different_samples = []\n",
    "accuracy_encoded = 0\n",
    "accuracy_decoded = 0\n",
    "ind = 0                                         #\n",
    "for sample in tqdm.tqdm(data):\n",
    "    # Decoded version\n",
    "    decoded_output = model.apply(sample[0]).decoded\n",
    "\n",
    "    # Encoded version\n",
    "#    encoded_input = model.input_encoder.encode(sample[0])\n",
    "    encoded_input = X[ind]                      #\n",
    "    logits = forward_fn.apply(model.params, jax.numpy.array([encoded_input])).unembedded_output\n",
    "    encoded_output = jnp.argmax(logits, axis=-1)[0]\n",
    "#    encoded_output = [\"BOS\"] + model.output_encoder.decode(encoded_output.tolist()[1:])\n",
    "    mask = jnp.ones_like(x)                     #\n",
    "    mask = mask.at[0].set(0)                    #\n",
    "    padMask = jnp.where(x!=padToken, mask, 0)   #\n",
    "\n",
    "\n",
    "    if decoded_output == sample[1]:\n",
    "        accuracy_decoded += 1\n",
    "    #if encoded_output == sample[1]:\n",
    "    if jnp.all(encoded_output*padMask == Y[ind]*padMask):\n",
    "        accuracy_encoded += 1\n",
    "\n",
    "    ind += 1                                    #\n",
    "\n",
    "    #if encoded_output != decoded_output:\n",
    "    #    different_samples.append((sample[0], encoded_output, decoded_output))\n",
    "\n",
    "print(f\"Accuracy encoded: {accuracy_encoded / len(data)}\")\n",
    "print(f\"Accuracy decoded: {accuracy_decoded / len(data)}\")\n",
    "\n",
    "print(f\"Different samples: {len(different_samples)}\")\n",
    "if len(different_samples) > 0:\n",
    "    print(different_samples[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
