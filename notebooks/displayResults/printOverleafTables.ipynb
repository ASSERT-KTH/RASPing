{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracr.rasp import rasp\n",
    "from tracr.compiler import compiling\n",
    "from tracr.compiler import lib\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.model import Model\n",
    "from src.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints the overleaf table body from a pandas dataframe\n",
    "def dataFrameToOverleafTableBody(df: pd.DataFrame, decimalNumber = 2):\n",
    "    columnCount = len(df.columns.values)\n",
    "    tableBody = \"\\\\begin{tabular}{|\"+ \"\".join([\"c|\" for i in range(columnCount)]) +\"} \\\\hline \\n\"\n",
    "    tableBody += \" & \".join(map(lambda x: \"\\\\textbf{\"+str(x)+\"}\", df.columns.values)) + \"\\\\\\\\ \\\\hline \\n\"\n",
    "    for _, row in df.iterrows():\n",
    "        if decimalNumber:\n",
    "            newRow = row.values[0] + \" & \"\n",
    "            newRow += \" & \".join(map(lambda x: \"%.2f\"%x, row.values[1:])) + \"\\\\\\\\ \\\\hline \\n\"\n",
    "        else:\n",
    "            newRow = \" & \".join(map(str, row.values)) + \"\\\\\\\\ \\\\hline \\n\"\n",
    "        tableBody += newRow\n",
    "    tableBody += \"\\\\end{tabular} \\n\"\n",
    "    return tableBody\n",
    "\n",
    "#Merge the results from the files in list. The files need to have the same dimension\n",
    "def loadArray(fileNames=\"temp\"):\n",
    "    if type(fileNames) is list and len(fileNames)==1:\n",
    "        fileNames = fileNames[0]\n",
    "\n",
    "    if type(fileNames) is list:\n",
    "        file = open(fileNames[0], \"rb\")\n",
    "        array = np.load(file).reshape((-1,1))\n",
    "        file.close()\n",
    "        for fn in fileNames[1:]:\n",
    "            file = open(fn, \"rb\")\n",
    "            conAcc = np.load(file).reshape((-1,1))\n",
    "            array = np.concatenate((array, conAcc), axis=1)\n",
    "            file.close()\n",
    "        \n",
    "    else:\n",
    "        file = open(fileNames, \"rb\")\n",
    "        array = np.load(file)\n",
    "        file.close()\n",
    "\n",
    "    return array\n",
    "\n",
    "#Returns all possible comnination of 'baseExpression' split at \"{}\" and filed with 'modificationsLists'\n",
    "def getListOfNames(baseExpression: str, modificationsLists: list):\n",
    "    listOfNames = []\n",
    "    splitBase = baseExpression.split(\"{}\")\n",
    "    if len(splitBase) != len(modificationsLists) + 1:\n",
    "        print(\"Error: Possible modifications (\"+str(len(splitBase)-1)+\") does not match given modifications (\"+str(len(modificationsLists))+\")\")\n",
    "        raise RuntimeError\n",
    "    \n",
    "    if len(splitBase) == 2:\n",
    "        for modification in modificationsLists[0]:\n",
    "            listOfNames.append(str(modification).join(splitBase))\n",
    "        return listOfNames\n",
    "    \n",
    "    for modification in modificationsLists[0]:\n",
    "        listOfNames += getListOfNames(splitBase[0] + str(modification) + \"{}\".join(splitBase[1:]), modificationsLists[1:])\n",
    "\n",
    "    return listOfNames\n",
    "\n",
    "#Creates and returns a list of names based on standard for each model test\n",
    "def createListOfNames(testName, baseDirectory = \"\", paramNames = None):\n",
    "    match testName:\n",
    "        case \"overTraining\":\n",
    "            if paramNames is None:\n",
    "                paramNames = [\"v1\", \"v2\", \"v3\"]\n",
    "            baseExpression = \"{}{}_{}_{}\"\n",
    "            modificationsLists = [[\"random_\", \"\"],\n",
    "                                  [\"train\", \"val\"],\n",
    "                                  [\"sort\", \"reverse\", \"hist\", \"most-freq\", \"shuffle_dyck1\", \"shuffle_dyck2\"],\n",
    "                                  paramNames]\n",
    "            nameList = getListOfNames(baseExpression, modificationsLists)\n",
    "        case \"bitFlip\":\n",
    "            pass\n",
    "\n",
    "        case \"gaussian\":\n",
    "            if paramNames is None:\n",
    "                paramNames = [\"0.01\", \"0.25\", \"0.50\", \"0.75\", \"1.0\", \"1.25\"]\n",
    "            baseExpression = \"{}_{}_{}_gaussian_std{}_{}\"\n",
    "            modificationsLists = [[\"sort\", \"reverse\", \"hist\", \"most-freq\", \"shuffle_dyck1\", \"shuffle_dyck2\"],\n",
    "                                 [\"train\", \"val\"],\n",
    "                                 [\"loss\", \"acc\"],\n",
    "                                 paramNames,\n",
    "                                 [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "                                 ]\n",
    "            nameList = getListOfNames(baseExpression, modificationsLists)\n",
    "\n",
    "        case \"mutated\":\n",
    "            pass\n",
    "        case _:\n",
    "            print(\"Error:\", testName, \"is not a valid test name\")\n",
    "        \n",
    "    nameList = [baseDirectory + name for name in nameList]\n",
    "\n",
    "    return nameList\n",
    "\n",
    "#Classify fileName according to model base and loss/acc\n",
    "def tagFileName(fileName):\n",
    "    tags = {}\n",
    "\n",
    "def dictAppend(dic, id, value):\n",
    "    if id in dic:\n",
    "        dic[id].append(value)\n",
    "    else:\n",
    "        dic[id]=[value]\n",
    "        \n",
    "def dataFrameHelper(dfDict, prefix, includedParameters, relevantFileNames, useAverage, useMean, useStd):\n",
    "    for param in includedParameters:\n",
    "        paramFileNames = [name for name in relevantFileNames if str(param) in name]\n",
    "\n",
    "        #Start adding to the fields\n",
    "        data = loadArray(paramFileNames)\n",
    "\n",
    "        if useAverage:\n",
    "            if useMean:\n",
    "                dictAppend(dfDict, prefix+\"mean\"+str(param), data.mean(axis=1)[-1])\n",
    "            if useStd:\n",
    "                dictAppend(dfDict, prefix+\"std\"+str(param), data.std(axis=1)[-1])\n",
    "        else:\n",
    "            dictAppend(dfDict, prefix+str(param), data[-1])\n",
    "\n",
    "def createDataFrameFromFileNames(fileNames, includedParameters, useAverage = True, useMean = True, useStd = True, includeTrain = False, includeValidation = True, includeLoss = False,\n",
    "                                  includeAcc = True, rowIsModel = True, includeRandom = False):\n",
    "    #Possible columns (All at certain checkpoints e.g. end, start, certain epoch)\n",
    "        #Mean, std\n",
    "\n",
    "    #Problem: Some experiments use mean others not (regular, grokking and mutations)\n",
    "        #Solution. If experiment uses mean it is consistent throughout, add as a parameter flag\n",
    "        #using average implies that we want to include mean and std. I'll add flag for min/max as well\n",
    "\n",
    "    #Problem: Currently only gives fileNames, I need model names extracted as well as loss/acc and train/validation\n",
    "    #This requires linking a model name, train/validation and loss/acc with corresponding fileNames\n",
    "        #Solution should be able to build a parser function which can classify each fileName by model name, loss/acc before extracting data \n",
    "        #Not good enough. I need to differentiate between model name, train/val, loss/acc and parameter value\n",
    "        #This suggests it should be easier to parse these from the baseExpression directly \n",
    "\n",
    "    dfDict = {}\n",
    "\n",
    "    #Sort results with row as model\n",
    "    if rowIsModel:\n",
    "        dfDict[\"Model\"]=[\"Sort\",\"Reverse\",\"Hist\",\"Most-Freq\",\"Dyck1\",\"Dyck2\"]\n",
    "\n",
    "        #Itterate trough all models\n",
    "        for modelName in [\"sort\", \"reverse\", \"hist\", \"most-freq\", \"dyck1\", \"dyck2\"]:\n",
    "            modelFileNames = [name for name in fileNames if modelName in name]\n",
    "\n",
    "            if includeRandom:\n",
    "                randomFileNames = [name for name in fileNames if \"random\" in name]\n",
    "\n",
    "                if includeTrain:\n",
    "                    trainFileNames = [name for name in randomFileNames if \"train\" in name]\n",
    "\n",
    "                    if includeAcc:\n",
    "                        accFileNames = [name for name in trainFileNames if \"acc\" in name]\n",
    "\n",
    "                        dataFrameHelper(dfDict, \"randta\", includedParameters, accFileNames, useAverage, useMean, useStd)\n",
    "\n",
    "                    if includeLoss:\n",
    "                        lossFileNames = [name for name in trainFileNames if \"loss\" in name]\n",
    "\n",
    "                        dataFrameHelper(dfDict, \"randtl\", includedParameters, lossFileNames, useAverage, useMean, useStd)\n",
    "\n",
    "                if includeValidation:\n",
    "                    valFileNames = [name for name in randomFileNames if \"val\" in name]\n",
    "\n",
    "                    if includeAcc:\n",
    "                        accFileNames = [name for name in valFileNames if \"acc\" in name]\n",
    "\n",
    "                        dataFrameHelper(dfDict, \"randva\", includedParameters, accFileNames, useAverage, useMean, useStd)\n",
    "\n",
    "                    if includeLoss:\n",
    "                        lossFileNames = [name for name in valFileNames if \"loss\" in name]\n",
    "\n",
    "                        dataFrameHelper(dfDict, \"randvl\", includedParameters, lossFileNames, useAverage, useMean, useStd)\n",
    "            \n",
    "            #Non random\n",
    "            else:\n",
    "                if includeTrain:\n",
    "                    trainFileNames = [name for name in modelFileNames if \"train\" in name]\n",
    "\n",
    "                    if includeAcc:\n",
    "                        accFileNames = [name for name in trainFileNames if \"acc\" in name]\n",
    "\n",
    "                        dataFrameHelper(dfDict, \"ta\", includedParameters, accFileNames, useAverage, useMean, useStd)\n",
    "\n",
    "                    if includeLoss:\n",
    "                        lossFileNames = [name for name in trainFileNames if \"loss\" in name]\n",
    "\n",
    "                        dataFrameHelper(dfDict, \"tl\", includedParameters, lossFileNames, useAverage, useMean, useStd)\n",
    "\n",
    "                if includeValidation:\n",
    "                    valFileNames = [name for name in modelFileNames if \"val\" in name]\n",
    "\n",
    "                    if includeAcc:\n",
    "                        accFileNames = [name for name in valFileNames if \"acc\" in name]\n",
    "\n",
    "                        dataFrameHelper(dfDict, \"va\", includedParameters, accFileNames, useAverage, useMean, useStd)\n",
    "\n",
    "                    if includeLoss:\n",
    "                        lossFileNames = [name for name in valFileNames if \"loss\" in name]\n",
    "\n",
    "                        dataFrameHelper(dfDict, \"vl\", includedParameters, lossFileNames, useAverage, useMean, useStd)\n",
    "                    \n",
    "    else:\n",
    "        print(\"Only model rows are implemented\")            \n",
    "\n",
    "    #Specially clause for regular overtraining results\n",
    "    if not (includeTrain or includeValidation):\n",
    "        print(\"Not yet implemented aka kinda useless at the moment\")\n",
    "        raise RuntimeError\n",
    "\n",
    "    return pd.DataFrame(dfDict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sort_loss_v1', 'sort_loss_v2', 'sort_loss_v3', 'reverse_loss_v1', 'reverse_loss_v2', 'reverse_loss_v3', 'hist_loss_v1', 'hist_loss_v2', 'hist_loss_v3', 'most-freq_loss_v1', 'most-freq_loss_v2', 'most-freq_loss_v3', 'dyck1_loss_v1', 'dyck1_loss_v2', 'dyck1_loss_v3', 'dyck2_loss_v1', 'dyck2_loss_v2', 'dyck2_loss_v3']\n"
     ]
    }
   ],
   "source": [
    "baseExpression = \"{}_{}_{}\"\n",
    "modificationsLists = [[\"sort\", \"reverse\", \"hist\", \"most-freq\", \"dyck1\", \"dyck2\"],\n",
    "                      [\"loss\", \"val\"],\n",
    "                      [\"v1\", \"v2\", \"v3\"]]\n",
    "\n",
    "fileNames = getListOfNames(baseExpression, modificationsLists)\n",
    "\n",
    "trainNames = [name for name in fileNames if \"loss\" in name]\n",
    "print(trainNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Gaussian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': ['Sort', 'Reverse', 'Hist', 'Most-Freq', 'Dyck1', 'Dyck2'], 'vamean0.01': [np.float64(0.9540453635694188), np.float64(0.9989399293286219), np.float64(1.0), np.float64(0.36214993118759575), np.float64(0.9122077922077922), np.float64(0.9297688791829039)], 'vamean0.25': [np.float64(0.9926956694855734), np.float64(0.9134318785882991), np.float64(1.0), np.float64(0.3772673303681378), np.float64(0.8449639249639249), np.float64(0.8932495121866124)], 'vamean0.50': [np.float64(0.9860010190514107), np.float64(1.0), np.float64(1.0), np.float64(0.35776090066823507), np.float64(0.852914862914863), np.float64(0.9116499233369891)], 'vamean0.75': [np.float64(0.9721664377635657), np.float64(0.9342949216224932), np.float64(1.0), np.float64(0.3726626781197031), np.float64(0.9127417027417029), np.float64(0.9001052778568539)], 'vamean1.0': [np.float64(0.9970043249742379), np.float64(0.8753108920711673), np.float64(1.0), np.float64(0.36418346276806324), np.float64(0.8668831168831168), np.float64(0.9385378530042174)], 'vamean1.25': [np.float64(0.9896504179658493), np.float64(0.6836547884613575), np.float64(1.0), np.float64(0.36251329051548026), np.float64(0.8767965367965369), np.float64(0.8840739163902096)]}\n",
      "\\begin{tabular}{|c|c|c|c|c|c|c|} \\hline \n",
      "\\textbf{Model} & \\textbf{vamean0.01} & \\textbf{vamean0.25} & \\textbf{vamean0.50} & \\textbf{vamean0.75} & \\textbf{vamean1.0} & \\textbf{vamean1.25}\\\\ \\hline \n",
      "Sort0.95 & 0.99 & 0.99 & 0.97 & 1.00 & 0.99\\\\ \\hline \n",
      "Reverse1.00 & 0.91 & 1.00 & 0.93 & 0.88 & 0.68\\\\ \\hline \n",
      "Hist1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00\\\\ \\hline \n",
      "Most-Freq0.36 & 0.38 & 0.36 & 0.37 & 0.36 & 0.36\\\\ \\hline \n",
      "Dyck10.91 & 0.84 & 0.85 & 0.91 & 0.87 & 0.88\\\\ \\hline \n",
      "Dyck20.93 & 0.89 & 0.91 & 0.90 & 0.94 & 0.88\\\\ \\hline \n",
      "\\end{tabular} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseDirectory = os.path.abspath(os.path.join('../..')) + \"/PerformanceTesting/savedData/noiseTrainingGaussian2/\"\n",
    "fileNames = createListOfNames(\"gaussian\", baseDirectory)\n",
    "df = createDataFrameFromFileNames(fileNames, includeTrain=False, useStd=False, useMean=True, includedParameters = [\"0.01\", \"0.25\", \"0.50\", \"0.75\", \"1.0\", \"1.25\"])\n",
    "print(dataFrameToOverleafTableBody(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Gaussian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': ['Sort', 'Reverse', 'Hist', 'Most-Freq', 'Dyck1', 'Dyck2'], 'vamean0.01': [np.float64(0.9540453635694188), np.float64(0.9989399293286219), np.float64(1.0), np.float64(0.36214993118759575), np.float64(0.9122077922077922), np.float64(0.9297688791829039)], 'vamean0.25': [np.float64(0.9926956694855734), np.float64(0.9134318785882991), np.float64(1.0), np.float64(0.3772673303681378), np.float64(0.8449639249639249), np.float64(0.8932495121866124)], 'vamean0.50': [np.float64(0.9860010190514107), np.float64(1.0), np.float64(1.0), np.float64(0.35776090066823507), np.float64(0.852914862914863), np.float64(0.9116499233369891)], 'vamean0.75': [np.float64(0.9721664377635657), np.float64(0.9342949216224932), np.float64(1.0), np.float64(0.3726626781197031), np.float64(0.9127417027417029), np.float64(0.9001052778568539)], 'vamean1.0': [np.float64(0.9970043249742379), np.float64(0.8753108920711673), np.float64(1.0), np.float64(0.36418346276806324), np.float64(0.8668831168831168), np.float64(0.9385378530042174)], 'vamean1.25': [np.float64(0.9896504179658493), np.float64(0.6836547884613575), np.float64(1.0), np.float64(0.36251329051548026), np.float64(0.8767965367965369), np.float64(0.8840739163902096)]}\n",
      "\\begin{tabular}{|c|c|c|c|c|c|c|} \\hline \n",
      "\\textbf{Model} & \\textbf{vamean0.01} & \\textbf{vamean0.25} & \\textbf{vamean0.50} & \\textbf{vamean0.75} & \\textbf{vamean1.0} & \\textbf{vamean1.25}\\\\ \\hline \n",
      "Sort0.95 & 0.99 & 0.99 & 0.97 & 1.00 & 0.99\\\\ \\hline \n",
      "Reverse1.00 & 0.91 & 1.00 & 0.93 & 0.88 & 0.68\\\\ \\hline \n",
      "Hist1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00\\\\ \\hline \n",
      "Most-Freq0.36 & 0.38 & 0.36 & 0.37 & 0.36 & 0.36\\\\ \\hline \n",
      "Dyck10.91 & 0.84 & 0.85 & 0.91 & 0.87 & 0.88\\\\ \\hline \n",
      "Dyck20.93 & 0.89 & 0.91 & 0.90 & 0.94 & 0.88\\\\ \\hline \n",
      "\\end{tabular} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseDirectory = os.path.abspath(os.path.join('../..')) + \"/PerformanceTesting/savedData/noiseTrainingGaussian2/\"\n",
    "fileNames = createListOfNames(\"gaussian\", baseDirectory)\n",
    "df = createDataFrameFromFileNames(fileNames, includeTrain=False, useStd=False, useMean=True, includedParameters = [\"0.01\", \"0.25\", \"0.50\", \"0.75\", \"1.0\", \"1.25\"])\n",
    "print(dataFrameToOverleafTableBody(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Gaussian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': ['Sort', 'Reverse', 'Hist', 'Most-Freq', 'Dyck1', 'Dyck2'], 'vamean0.01': [np.float64(0.9540453635694188), np.float64(0.9989399293286219), np.float64(1.0), np.float64(0.36214993118759575), np.float64(0.9122077922077922), np.float64(0.9297688791829039)], 'vamean0.25': [np.float64(0.9926956694855734), np.float64(0.9134318785882991), np.float64(1.0), np.float64(0.3772673303681378), np.float64(0.8449639249639249), np.float64(0.8932495121866124)], 'vamean0.50': [np.float64(0.9860010190514107), np.float64(1.0), np.float64(1.0), np.float64(0.35776090066823507), np.float64(0.852914862914863), np.float64(0.9116499233369891)], 'vamean0.75': [np.float64(0.9721664377635657), np.float64(0.9342949216224932), np.float64(1.0), np.float64(0.3726626781197031), np.float64(0.9127417027417029), np.float64(0.9001052778568539)], 'vamean1.0': [np.float64(0.9970043249742379), np.float64(0.8753108920711673), np.float64(1.0), np.float64(0.36418346276806324), np.float64(0.8668831168831168), np.float64(0.9385378530042174)], 'vamean1.25': [np.float64(0.9896504179658493), np.float64(0.6836547884613575), np.float64(1.0), np.float64(0.36251329051548026), np.float64(0.8767965367965369), np.float64(0.8840739163902096)]}\n",
      "\\begin{tabular}{|c|c|c|c|c|c|c|} \\hline \n",
      "\\textbf{Model} & \\textbf{vamean0.01} & \\textbf{vamean0.25} & \\textbf{vamean0.50} & \\textbf{vamean0.75} & \\textbf{vamean1.0} & \\textbf{vamean1.25}\\\\ \\hline \n",
      "Sort0.95 & 0.99 & 0.99 & 0.97 & 1.00 & 0.99\\\\ \\hline \n",
      "Reverse1.00 & 0.91 & 1.00 & 0.93 & 0.88 & 0.68\\\\ \\hline \n",
      "Hist1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00\\\\ \\hline \n",
      "Most-Freq0.36 & 0.38 & 0.36 & 0.37 & 0.36 & 0.36\\\\ \\hline \n",
      "Dyck10.91 & 0.84 & 0.85 & 0.91 & 0.87 & 0.88\\\\ \\hline \n",
      "Dyck20.93 & 0.89 & 0.91 & 0.90 & 0.94 & 0.88\\\\ \\hline \n",
      "\\end{tabular} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseDirectory = os.path.abspath(os.path.join('../..')) + \"/PerformanceTesting/savedData/noiseTrainingGaussian2/\"\n",
    "fileNames = createListOfNames(\"gaussian\", baseDirectory)\n",
    "df = createDataFrameFromFileNames(fileNames, includeTrain=False, useStd=False, useMean=True, includedParameters = [\"0.01\", \"0.25\", \"0.50\", \"0.75\", \"1.0\", \"1.25\"])\n",
    "print(dataFrameToOverleafTableBody(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
