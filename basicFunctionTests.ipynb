{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "jaxlib version 0.4.26 is newer than and incompatible with jax version 0.4.21. Please update your jax and/or jaxlib packages.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\00tho\\anaconda3\\envs\\RASP\\Lib\\site-packages\\jax\\__init__.py:39\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _cloud_tpu_init\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Confusingly there are two things named \"config\": the module and the class.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# We want the exported object to be the class, so we first import the module\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# to make sure a later import doesn't overwrite the class.\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _config_module\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _config_module\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Force early import, allowing use of `jax.core` after importing `jax`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\00tho\\anaconda3\\envs\\RASP\\Lib\\site-packages\\jax\\config.py:15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 The JAX Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _deprecated_config  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Deprecations\u001b[39;00m\n\u001b[0;32m     19\u001b[0m _deprecations \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Added October 27, 2023\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing jax.config via the jax.config submodule is deprecated.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m         _deprecated_config),\n\u001b[0;32m     24\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\00tho\\anaconda3\\envs\\RASP\\Lib\\site-packages\\jax\\_src\\config.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Generic, NamedTuple, NoReturn, Optional, TypeVar\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jax_jit\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transfer_guard_lib\n",
      "File \u001b[1;32mc:\\Users\\00tho\\anaconda3\\envs\\RASP\\Lib\\site-packages\\jax\\_src\\lib\\__init__.py:74\u001b[0m\n\u001b[0;32m     70\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _jaxlib_version\n\u001b[0;32m     73\u001b[0m version_str \u001b[38;5;241m=\u001b[39m jaxlib\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m---> 74\u001b[0m version \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_jaxlib_version\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjax_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjaxlib_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaxlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m  \u001b[49m\u001b[43mminimum_jaxlib_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_minimum_jaxlib_version\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Before importing any C compiled modules from jaxlib, first import the CPU\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# feature guard module to verify that jaxlib was compiled in a way that only\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# uses instructions that are present on this machine.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpu_feature_guard\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcpu_feature_guard\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\00tho\\anaconda3\\envs\\RASP\\Lib\\site-packages\\jax\\_src\\lib\\__init__.py:66\u001b[0m, in \u001b[0;36mcheck_jaxlib_version\u001b[1;34m(jax_version, jaxlib_version, minimum_jaxlib_version)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _jaxlib_version \u001b[38;5;241m>\u001b[39m _jax_version:\n\u001b[1;32m---> 66\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     67\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjaxlib version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjaxlib_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is newer than and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     68\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincompatible with jax version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjax_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     69\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate your jax and/or jaxlib packages.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _jaxlib_version\n",
      "\u001b[1;31mRuntimeError\u001b[0m: jaxlib version 0.4.26 is newer than and incompatible with jax version 0.4.21. Please update your jax and/or jaxlib packages."
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The default of float16 can lead to discrepancies between outputs of\n",
    "# the compiled model and the RASP program.\n",
    "jax.config.update('jax_default_matmul_precision', 'float32')\n",
    "\n",
    "from tracr.compiler import compiling\n",
    "from tracr.compiler import lib\n",
    "from tracr.rasp import rasp\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"src\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mModel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mc:\\Users\\00tho\\Documents\\Courses\\DegreeProject\\RASPing\\src\\functions.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\00tho\\anaconda3\\envs\\RASP\\Lib\\site-packages\\jax\\__init__.py:39\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _cloud_tpu_init\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Confusingly there are two things named \"config\": the module and the class.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# We want the exported object to be the class, so we first import the module\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# to make sure a later import doesn't overwrite the class.\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _config_module\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _config_module\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Force early import, allowing use of `jax.core` after importing `jax`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\00tho\\anaconda3\\envs\\RASP\\Lib\\site-packages\\jax\\config.py:15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 The JAX Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _deprecated_config  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Deprecations\u001b[39;00m\n\u001b[0;32m     19\u001b[0m _deprecations \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Added October 27, 2023\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing jax.config via the jax.config submodule is deprecated.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m         _deprecated_config),\n\u001b[0;32m     24\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\00tho\\anaconda3\\envs\\RASP\\Lib\\site-packages\\jax\\_src\\config.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Generic, NamedTuple, NoReturn, Optional, TypeVar\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jax_jit\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transfer_guard_lib\n",
      "File \u001b[1;32mc:\\Users\\00tho\\anaconda3\\envs\\RASP\\Lib\\site-packages\\jax\\_src\\lib\\__init__.py:75\u001b[0m\n\u001b[0;32m     70\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _jaxlib_version\n\u001b[0;32m     73\u001b[0m version_str \u001b[38;5;241m=\u001b[39m jaxlib\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39m__version__\n\u001b[0;32m     74\u001b[0m version \u001b[38;5;241m=\u001b[39m check_jaxlib_version(\n\u001b[1;32m---> 75\u001b[0m   jax_version\u001b[38;5;241m=\u001b[39m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241m.\u001b[39m__version__,\n\u001b[0;32m     76\u001b[0m   jaxlib_version\u001b[38;5;241m=\u001b[39mjaxlib\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39m__version__,\n\u001b[0;32m     77\u001b[0m   minimum_jaxlib_version\u001b[38;5;241m=\u001b[39mjax\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39m_minimum_jaxlib_version)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Before importing any C compiled modules from jaxlib, first import the CPU\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# feature guard module to verify that jaxlib was compiled in a way that only\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# uses instructions that are present on this machine.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpu_feature_guard\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcpu_feature_guard\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "from src.functions import *\n",
    "from src.Model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['BOS', '{', '}'], ['BOS', 1, 1]), (['BOS', '(', ')'], ['BOS', 1, 1]), (['BOS', ')', '(', '(', '{'], ['BOS', 0, 0, 0, 0]), (['BOS', '{', '}', '{', '}'], ['BOS', 1, 1, 1, 1]), (['BOS', '(', ')', '{', '('], ['BOS', 0, 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "#Check that data can be generated\n",
    "data = generateData(\"shuffle_dyck2\", 5, 100)\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dyck1\n",
      "Percentage of data which is:\n",
      "Of odd length: 12.55\n",
      "Balanced: 42.95\n",
      "Percentage of data which is:\n",
      "Of odd length: 8.89\n",
      "Balanced: 48.83\n",
      "Percentage of data which is:\n",
      "Of odd length: 12.88\n",
      "Balanced: 47.76\n",
      "Percentage of data which is:\n",
      "Of odd length: 11.6\n",
      "Balanced: 52.58\n",
      "\n",
      "dyck2\n",
      "Percentage of data which is:\n",
      "Of odd length: 12.46\n",
      "Balanced: 41.56\n",
      "Percentage of data which is:\n",
      "Of odd length: 8.45\n",
      "Balanced: 48.38\n",
      "Percentage of data which is:\n",
      "Of odd length: 12.15\n",
      "Balanced: 47.63\n",
      "Percentage of data which is:\n",
      "Of odd length: 11.46\n",
      "Balanced: 52.11\n"
     ]
    }
   ],
   "source": [
    "#Print some statistics on the dyck data to check for balancing\n",
    "print(\"dyck1\")\n",
    "checkDyckBalance(generateData(\"shuffle_dyck1\", 5, 10000))\n",
    "checkDyckBalance(generateData(\"shuffle_dyck1\", 10, 10000))\n",
    "checkDyckBalance(generateData(\"shuffle_dyck1\", 15, 10000))\n",
    "checkDyckBalance(generateData(\"shuffle_dyck1\", 50, 10000))\n",
    "\n",
    "print(\"\\ndyck2\")\n",
    "checkDyckBalance(generateData(\"shuffle_dyck2\", 5, 10000))\n",
    "checkDyckBalance(generateData(\"shuffle_dyck2\", 10, 10000))\n",
    "checkDyckBalance(generateData(\"shuffle_dyck2\", 15, 10000))\n",
    "checkDyckBalance(generateData(\"shuffle_dyck2\", 50, 10000))\n",
    "\n",
    "#Seems to work fairly well, roughly between 40 and 50% is balanced depending on the maximum size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['BOS', '(', ')'], ['BOS', 1, 1]), (['BOS', '}', '{'], ['BOS', 0, 0]), (['BOS', '(', ')', '}', '{'], ['BOS', 0, 0, 0, 0]), (['BOS', '{', '}', '(', '{'], ['BOS', 0, 0, 0, 0]), (['BOS', '}', '('], ['BOS', 0, 0])]\n",
      "Evaluating model: shuffle_dyck2\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Making sure the entire pipeline for testing the model works\n",
    "name = \"shuffle_dyck2\"\n",
    "maxSeqLen = 5\n",
    "data = generateData(name, maxSeqLen, 1000)\n",
    "model = generateModel(name, maxSeqLen)\n",
    "\n",
    "print(data[:5])\n",
    "\n",
    "booleanAccuracy = model.evaluateModel(data)\n",
    "accuracy=np.mean(booleanAccuracy)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "(['BOS', '{', '}'], ['BOS', 1, 1])\n",
      "['BOS', True, True]\n"
     ]
    }
   ],
   "source": [
    "#How to look at specific data points\n",
    "print(np.argwhere(booleanAccuracy-1))   #Numpy list where evaluation failed\n",
    "print(data[7])\n",
    "\n",
    "print(model.apply(data[7][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerConfig(num_heads=1, num_layers=4, key_size=12, mlp_hidden_size=30, dropout_rate=0.0, activation_function=<jax._src.custom_derivatives.custom_jvp object at 0x0000023449621CA0>, layer_norm=False, causal=False)\n",
      "\n",
      "Layer analysis:\n",
      "pos_embed\n",
      "\t embeddings\n",
      "\t  N: 270\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 98.15\n",
      "token_embed\n",
      "\t embeddings\n",
      "\t  N: 315\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 95.56\n",
      "transformer/layer_0/attn/key\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 98.89\n",
      "transformer/layer_0/attn/linear\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 99.81\n",
      "transformer/layer_0/attn/query\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/100.00\t nValues: 2\t percentageZero: 95.19\n",
      "transformer/layer_0/attn/value\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 99.81\n",
      "transformer/layer_0/mlp/linear_1\n",
      "\t w\n",
      "\t  N: 1350\t min/max: -75.00/100.00\t nValues: 13\t percentageZero: 98.37\n",
      "transformer/layer_0/mlp/linear_2\n",
      "\t w\n",
      "\t  N: 1350\t min/max: -1.00/1.00\t nValues: 3\t percentageZero: 98.30\n",
      "transformer/layer_1/attn/key\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/0.00\t nValues: 1\t percentageZero: 100.00\n",
      "transformer/layer_1/attn/linear\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/0.00\t nValues: 1\t percentageZero: 100.00\n",
      "transformer/layer_1/attn/query\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/0.00\t nValues: 1\t percentageZero: 100.00\n",
      "transformer/layer_1/attn/value\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/0.00\t nValues: 1\t percentageZero: 100.00\n",
      "transformer/layer_1/mlp/linear_1\n",
      "\t w\n",
      "\t  N: 1350\t min/max: -1.00/1.00\t nValues: 3\t percentageZero: 93.33\n",
      "transformer/layer_1/mlp/linear_2\n",
      "\t w\n",
      "\t  N: 1350\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 97.78\n",
      "transformer/layer_2/attn/key\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/0.00\t nValues: 1\t percentageZero: 100.00\n",
      "transformer/layer_2/attn/linear\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/0.00\t nValues: 1\t percentageZero: 100.00\n",
      "transformer/layer_2/attn/query\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/0.00\t nValues: 1\t percentageZero: 100.00\n",
      "transformer/layer_2/attn/value\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/0.00\t nValues: 1\t percentageZero: 100.00\n",
      "transformer/layer_2/mlp/linear_1\n",
      "\t w\n",
      "\t  N: 1350\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 99.26\n",
      "transformer/layer_2/mlp/linear_2\n",
      "\t w\n",
      "\t  N: 1350\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 99.26\n",
      "transformer/layer_3/attn/key\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 98.89\n",
      "transformer/layer_3/attn/linear\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 99.07\n",
      "transformer/layer_3/attn/query\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/100.00\t nValues: 3\t percentageZero: 98.89\n",
      "transformer/layer_3/attn/value\n",
      "\t w\n",
      "\t  N: 540\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 99.07\n",
      "transformer/layer_3/mlp/linear_1\n",
      "\t w\n",
      "\t  N: 1350\t min/max: 0.00/0.00\t nValues: 1\t percentageZero: 100.00\n",
      "transformer/layer_3/mlp/linear_2\n",
      "\t w\n",
      "\t  N: 1350\t min/max: 0.00/0.00\t nValues: 1\t percentageZero: 100.00\n",
      "total\n",
      "\t  N: 20649\t min/max: -75.00/100.00\t nValues: 15\t percentageZero: 98.74\n"
     ]
    }
   ],
   "source": [
    "#Quick function to check for if all \"b\" weights are truly zero\n",
    "def analyzeB(model: Model):\n",
    "    for name1, layer in model.model.params.items():\n",
    "        for name2, weight in layer.items():\n",
    "            if name2!=\"b\":\n",
    "                continue\n",
    "            weightCounter = {}\n",
    "\n",
    "            #Find unique weights and count instances for the weights\n",
    "            for t in weight.flatten():\n",
    "                t = float(t)\n",
    "                if t in weightCounter:\n",
    "                    weightCounter[t]+=1\n",
    "                else:\n",
    "                    weightCounter[t]=1\n",
    "\n",
    "            from src.Model import calculateWeightStatistics\n",
    "\n",
    "            calculateWeightStatistics(weightCounter, True)\n",
    "\n",
    "#name = \"reverse\"\n",
    "name = \"reverse\"\n",
    "maxSeqLen = 5\n",
    "data = generateData(name, maxSeqLen, 1000)\n",
    "model = generateModel(name, maxSeqLen)\n",
    "\n",
    "#Display weight layer statistics of the model\n",
    "#analyzeB(model)\n",
    "model.updateWeightStatistics()\n",
    "model.printWeightStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerConfig(num_heads=1, num_layers=4, key_size=12, mlp_hidden_size=30, dropout_rate=0.0, activation_function=<jax._src.custom_derivatives.custom_jvp object at 0x0000023449621CA0>, layer_norm=False, causal=False)\n",
      "\n",
      "Layer analysis:\n",
      "pos_embed\n",
      "\t embeddings\n",
      "\t  N: 270\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 98.15\n",
      "token_embed\n",
      "\t embeddings\n",
      "\t  N: 315\t min/max: 0.00/1.00\t nValues: 2\t percentageZero: 95.56\n",
      "transformer/layer_0/attn/key\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/1.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_0/attn/linear\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/1.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_0/attn/query\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/100.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_0/attn/value\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/1.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_0/mlp/linear_1\n",
      "\t w\n",
      "\t  N: 1350\t min/max: -75.00/100.00\t nValues: 1350\t percentageZero: 0.00\n",
      "transformer/layer_0/mlp/linear_2\n",
      "\t w\n",
      "\t  N: 1350\t min/max: -1.00/1.00\t nValues: 1350\t percentageZero: 0.00\n",
      "transformer/layer_1/attn/key\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/0.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_1/attn/linear\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/0.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_1/attn/query\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/0.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_1/attn/value\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/0.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_1/mlp/linear_1\n",
      "\t w\n",
      "\t  N: 1350\t min/max: -1.00/1.00\t nValues: 1350\t percentageZero: 0.00\n",
      "transformer/layer_1/mlp/linear_2\n",
      "\t w\n",
      "\t  N: 1350\t min/max: -0.00/1.00\t nValues: 1350\t percentageZero: 0.00\n",
      "transformer/layer_2/attn/key\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/0.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_2/attn/linear\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/0.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_2/attn/query\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/0.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_2/attn/value\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/0.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_2/mlp/linear_1\n",
      "\t w\n",
      "\t  N: 1350\t min/max: -0.00/1.00\t nValues: 1350\t percentageZero: 0.00\n",
      "transformer/layer_2/mlp/linear_2\n",
      "\t w\n",
      "\t  N: 1350\t min/max: -0.00/1.00\t nValues: 1350\t percentageZero: 0.00\n",
      "transformer/layer_3/attn/key\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/1.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_3/attn/linear\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/1.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_3/attn/query\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/100.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_3/attn/value\n",
      "\t w\n",
      "\t  N: 540\t min/max: -0.00/1.00\t nValues: 540\t percentageZero: 0.00\n",
      "transformer/layer_3/mlp/linear_1\n",
      "\t w\n",
      "\t  N: 1350\t min/max: -0.00/0.00\t nValues: 1350\t percentageZero: 0.00\n",
      "transformer/layer_3/mlp/linear_2\n",
      "\t w\n",
      "\t  N: 1350\t min/max: -0.00/0.00\t nValues: 1350\t percentageZero: 0.00\n",
      "total\n",
      "\t  N: 20649\t min/max: -75.00/100.00\t nValues: 19438\t percentageZero: 5.76\n"
     ]
    }
   ],
   "source": [
    "#Testing adding noise \n",
    "name = \"reverse\"\n",
    "maxSeqLen = 5\n",
    "model = generateModel(name, maxSeqLen)\n",
    "model.addNoise(noiseType=\"gaussian\", amount=1.0, param=0.001)\n",
    "model.updateWeightStatistics()\n",
    "model.printWeightStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: reverse\n",
      "Accuracy: 0.991\n"
     ]
    }
   ],
   "source": [
    "#Testing evaluating model after adding noise\n",
    "data = generateData(name, maxSeqLen, 1000)\n",
    "booleanAccuracy = model.evaluateModel(data)\n",
    "accuracy=np.mean(booleanAccuracy)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function without_apply_rng.<locals>.apply_fn at 0x00000234649C8220>\n",
      "--------\n",
      "<function without_apply_rng.<locals>.apply_fn at 0x00000234649C87C0>\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "#Trying to figure out what kind of haiku model the tracr models are (how do they relate to pure haiku models) and how I can train these models\n",
    "\n",
    "#A non-stochastic simple haiku model\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "\n",
    "class MyLinear1(hk.Module):\n",
    "\n",
    "    def __init__(self, output_size, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "        j, k = x.shape[-1], self.output_size\n",
    "        w_init = hk.initializers.TruncatedNormal(1. / np.sqrt(j))\n",
    "        w = hk.get_parameter(\"w\", shape=[j, k], dtype=x.dtype, init=w_init)\n",
    "        b = hk.get_parameter(\"b\", shape=[k], dtype=x.dtype, init=jnp.ones)\n",
    "        return jnp.dot(x, w) + b\n",
    "\n",
    "def _forward_fn_linear1(x):\n",
    "    module = MyLinear1(output_size=2)\n",
    "    return module(x)\n",
    "\n",
    "haikuModel = hk.without_apply_rng(hk.transform(_forward_fn_linear1))\n",
    "\n",
    "#Tracr model\n",
    "tracrModel = generateModel(\"sort\", 5).model\n",
    "\n",
    "tracrModel.get_compiled_model\n",
    "\n",
    "print(haikuModel.apply)\n",
    "print(\"--------\")\n",
    "print(tracrModel.forward)\n",
    "print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "#### Testing the base functions and generating the test data\n",
    "\n",
    "The sort function does not have a 100% accuracy. This only seems to apply when including input token 0, if only using 1 and up it seems to work. A cursory analysis would suggest that the min value in the sort function is multiplied with the indicies which makes it indistinguishable if the minimum value is 1.\n",
    "\n",
    "The most-freq function does not work in the same method as the original RASP paper (despite the Tracr paper claiming they recreated the RASP function in Tracr). Instead of backfilling with BOS tokens it simply sorts all tokens in groups. The most-freq function (make_sort_freq) is also hardcoded to only accept 1 as the min_key value for some reason. I could fix this but it is not really a high priority (and seemingly breaks the sort function)\n",
    "\n",
    "The most-freq function seems to fail sometimes (always?) when there are mutiple groups of the same count. Maybe they did not actually sort the output based on token grupings and only on frequency? Need to check. That apears to be the case. The Tracr make_sort_freq function is lazy and does not differentiate between tokens as long as the count is the same.\n",
    "\n",
    "Shuffle dyck \n",
    "* The RASP paper uses the tokens T, P and F to account for if a dyck-k sequence is legal, possible legal or not legal for each token in the sequence. The Tracr implementation on the other hand only uses 1 or 0 to show if the entire sequence is legal or not. This is a far simpler solution yet for some reason they explicitly claim that this is how it is implemented in the RASP paper in their code ???\n",
    "* If tokens are randomly selected most sequences will be unblanaced e.g. only even sequences can be balanced and if the sequence starts with a end token it wll be unblanced.\n",
    "* I should probably try to generate the sequence such that the probability of a balanced sequence is roughly 50%\n",
    "\n",
    "#### Analyzing weights\n",
    "\n",
    "What do I need to look out for? All of these should probably be applied layerwise (for each matrix of weights) and globally\n",
    "* Maximum/minimum values?\n",
    "* Binary values?\n",
    "* All same values?\n",
    "* Percentage which is 0?\n",
    "\n",
    "It seems like all of the \"b\" weights are zero vectors for the given models. As such I feel like I should mostly stay away from those vectors when adding noise and training\n",
    "\n",
    "Many of the layer weights are zero. The layer weights are usually binary or ternary, very rarely do the layer assume more values than 3.\n",
    "\n",
    "The percentage of values which are zero is usually between 90 and 100%.\n",
    "\n",
    "#### Adding noise\n",
    "\n",
    "Flipping a set amunt of bits will often have no effect. The influence of a flipped bit is heavily dependent on which bit is flipped. I cannot say what specific bits are highly influential though. This behaviour strikes me as odd since I would intuit that binary weights are done so for a reason, that is all weights should be relevant at some points.\n",
    "\n",
    "Adding gaussian noise seems to give a better range of failure. The failed percentage increases \"exponentially\"ish with how large the noise is unlike bitflips which can cause large errors or no difference by flipping a single bit.\n",
    "\n",
    "#### Training\n",
    "\n",
    "Haiku is needlessly complicated. E.g. generating new sequences requires manually updating the rng_key each time instead of doing it within the functions themselves. Everything is wrapped with mutplie layers of functions and classes which makes it very difficult to keep track of what is what\n",
    "\n",
    "The tracr models are of the AssembledTransformerModel class which can be found in the tracr directory under tracr/tracr/compiler/assemble.py. The class seems to be a wrapper which contains things such as the parameters, configuration parameters and the forward pass function of a haiku model\n",
    "\n",
    "I cannot seem to find a convenient method to train a haiku model (like for example how a sklearn model assumes you want to train it from data). As such I think I need to figure out how a transformer is trained and manually apply that training to the parameters in a training loop. \n",
    "\n",
    "    Note, the haiku documentation for gradients states that \"You only need this in a very specific case that you want to take a gradient inside a transform()ed function and the function you are differentiating uses set_state()\". I am not sure what exactly this entails but it sound like they expect you to not use the grad function usually even though they do use the grad function in their \"training a subset of parameters\" example\n",
    "\n",
    "Quickly look into the VectorQuantisizer as it return some loss for optimizer, whatever that means. Referenced paper suggests it is used for training\n",
    "\n",
    "Look into the optax library. Seems to be perfect for what I want. At least if \"https://github.com/google-deepmind/dm-haiku/blob/main/examples/transformer/train.py\" is anything to go by\n",
    "\n",
    "If I use softmax I run the risk of trying to train even on the samples which are correct. No clue if this is a problem or not though lol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RASP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
