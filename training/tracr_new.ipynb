{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracr.rasp import rasp\n",
    "\n",
    "def make_sort_unique(vals: rasp.SOp, keys: rasp.SOp) -> rasp.SOp:\n",
    "  \"\"\"Returns vals sorted by < relation on keys.\n",
    "\n",
    "  Only supports unique keys.\n",
    "\n",
    "  Example usage:\n",
    "    sort = make_sort(rasp.tokens, rasp.tokens)\n",
    "    sort([2, 4, 3, 1])\n",
    "    >> [1, 2, 3, 4]\n",
    "\n",
    "  Args:\n",
    "    vals: Values to sort.\n",
    "    keys: Keys for sorting.\n",
    "  \"\"\"\n",
    "  smaller = rasp.Select(keys, keys, rasp.Comparison.LT).named(\"smaller\")\n",
    "  target_pos = rasp.SelectorWidth(smaller).named(\"target_pos\")\n",
    "  sel_new = rasp.Select(target_pos, rasp.indices, rasp.Comparison.EQ)\n",
    "  return rasp.Aggregate(sel_new, vals).named(\"sort\")\n",
    "\n",
    "\n",
    "def make_sort(vals: rasp.SOp, keys: rasp.SOp, *, max_seq_len: int,\n",
    "              min_key: float) -> rasp.SOp:\n",
    "  \"\"\"Returns vals sorted by < relation on keys, which don't need to be unique.\n",
    "\n",
    "  The implementation differs from the RASP paper, as it avoids using\n",
    "  compositions of selectors to break ties. Instead, it uses the arguments\n",
    "  max_seq_len and min_key to ensure the keys are unique.\n",
    "\n",
    "  Note that this approach only works for numerical keys.\n",
    "\n",
    "  Example usage:\n",
    "    sort = make_sort(rasp.tokens, rasp.tokens, 5, 1)\n",
    "    sort([2, 4, 3, 1])\n",
    "    >> [1, 2, 3, 4]\n",
    "    sort([2, 4, 1, 2])\n",
    "    >> [1, 2, 2, 4]\n",
    "\n",
    "  Args:\n",
    "    vals: Values to sort.\n",
    "    keys: Keys for sorting.\n",
    "    max_seq_len: Maximum sequence length (used to ensure keys are unique)\n",
    "    min_key: Minimum key value (used to ensure keys are unique)\n",
    "\n",
    "  Returns:\n",
    "    Output SOp of sort program.\n",
    "  \"\"\"\n",
    "  keys = rasp.SequenceMap(lambda x, i: x + min_key * i / max_seq_len, keys,\n",
    "                          rasp.indices)\n",
    "  return make_sort_unique(vals, keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerConfig(num_heads=1, num_layers=3, key_size=27, mlp_hidden_size=25, dropout_rate=0.0, activation_function=<jax._src.custom_derivatives.custom_jvp object at 0x76723c6b76e0>, layer_norm=False, causal=False)\n"
     ]
    }
   ],
   "source": [
    "from tracr.compiler import compiling\n",
    "\n",
    "sort = make_sort(rasp.tokens, rasp.tokens, max_seq_len=20, min_key=1)\n",
    "bos = \"BOS\"\n",
    "max_seq_len=5\n",
    "model = compiling.compile_rasp_to_model(\n",
    "    sort,\n",
    "    vocab={10, 20, 30, 40, 50},\n",
    "    max_seq_len=max_seq_len,\n",
    "    compiler_bos=bos,\n",
    ")\n",
    "print(model.model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracr.rasp import rasp\n",
    "\n",
    "def make_sort_unique_buggy(vals: rasp.SOp, keys: rasp.SOp) -> rasp.SOp:\n",
    "  \"\"\"Returns vals sorted by < relation on keys.\n",
    "\n",
    "  Only supports unique keys.\n",
    "\n",
    "  Example usage:\n",
    "    sort = make_sort(rasp.tokens, rasp.tokens)\n",
    "    sort([2, 4, 3, 1])\n",
    "    >> [1, 2, 3, 4]\n",
    "\n",
    "  Args:\n",
    "    vals: Values to sort.\n",
    "    keys: Keys for sorting.\n",
    "  \"\"\"\n",
    "  # BUG: GT instead of LT, resulting in descending order instead of ascending\n",
    "  smaller = rasp.Select(keys, keys, rasp.Comparison.GT).named(\"smaller\")\n",
    "  target_pos = rasp.SelectorWidth(smaller).named(\"target_pos\")\n",
    "  sel_new = rasp.Select(target_pos, rasp.indices, rasp.Comparison.EQ)\n",
    "  return rasp.Aggregate(sel_new, vals).named(\"sort\")\n",
    "\n",
    "\n",
    "def make_sort_buggy(vals: rasp.SOp, keys: rasp.SOp, *, max_seq_len: int,\n",
    "              min_key: float) -> rasp.SOp:\n",
    "  \"\"\"Returns vals sorted by < relation on keys, which don't need to be unique.\n",
    "\n",
    "  The implementation differs from the RASP paper, as it avoids using\n",
    "  compositions of selectors to break ties. Instead, it uses the arguments\n",
    "  max_seq_len and min_key to ensure the keys are unique.\n",
    "\n",
    "  Note that this approach only works for numerical keys.\n",
    "\n",
    "  Example usage:\n",
    "    sort = make_sort(rasp.tokens, rasp.tokens, 5, 1)\n",
    "    sort([2, 4, 3, 1])\n",
    "    >> [1, 2, 3, 4]\n",
    "    sort([2, 4, 1, 2])\n",
    "    >> [1, 2, 2, 4]\n",
    "\n",
    "  Args:\n",
    "    vals: Values to sort.\n",
    "    keys: Keys for sorting.\n",
    "    max_seq_len: Maximum sequence length (used to ensure keys are unique)\n",
    "    min_key: Minimum key value (used to ensure keys are unique)\n",
    "\n",
    "  Returns:\n",
    "    Output SOp of sort program.\n",
    "  \"\"\"\n",
    "  keys = rasp.SequenceMap(lambda x, i: x + min_key * i / max_seq_len, keys,\n",
    "                          rasp.indices)\n",
    "  return make_sort_unique_buggy(vals, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerConfig(num_heads=1, num_layers=3, key_size=27, mlp_hidden_size=25, dropout_rate=0.0, activation_function=<jax._src.custom_derivatives.custom_jvp object at 0x76723c6b76e0>, layer_norm=False, causal=False)\n",
      "TransformerConfig(num_heads=1, num_layers=3, key_size=27, mlp_hidden_size=25, dropout_rate=0.0, activation_function=<jax._src.custom_derivatives.custom_jvp object at 0x76723c6b76e0>, layer_norm=False, causal=False)\n"
     ]
    }
   ],
   "source": [
    "from tracr.compiler import compiling\n",
    "\n",
    "sort = make_sort(rasp.tokens, rasp.tokens, max_seq_len=20, min_key=1)\n",
    "bos = \"BOS\"\n",
    "max_seq_len=5\n",
    "model = compiling.compile_rasp_to_model(\n",
    "    sort,\n",
    "    vocab={10, 20, 30, 40, 50},\n",
    "    max_seq_len=max_seq_len,\n",
    "    compiler_bos=bos,\n",
    ")\n",
    "print(model.model_config)\n",
    "\n",
    "\n",
    "buggy_sort = make_sort_buggy(rasp.tokens, rasp.tokens, max_seq_len=20, min_key=1)\n",
    "bos = \"BOS\"\n",
    "max_seq_len=5\n",
    "buggy_model = compiling.compile_rasp_to_model(\n",
    "    buggy_sort,\n",
    "    vocab={10, 20, 30, 40, 50},\n",
    "    max_seq_len=max_seq_len,\n",
    "    compiler_bos=bos,\n",
    ")\n",
    "print(buggy_model.model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n",
      "(860, 6)\n",
      "(774, 6) (86, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "acceptedTokens = [10, 20, 30, 40, 50]\n",
    "maxSeqLength = max_seq_len\n",
    "size = 1000\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in range(size):\n",
    "    # TODO: implement padding for training\n",
    "    # inputLength = np.random.randint(2, maxSeqLength+1)  #Uniformly distributed between 2 and max length\n",
    "    inputLength = maxSeqLength\n",
    "\n",
    "    inputSeq = []\n",
    "    outputSeq = []\n",
    "    for t in np.random.choice(acceptedTokens, inputLength):\n",
    "        inputSeq.append(t)\n",
    "        outputSeq.append(t)\n",
    "\n",
    "    inputSeq.insert(0, bos)\n",
    "    outputSeq.sort()\n",
    "    outputSeq.insert(0, 10) # The output_encoder does has a None bos_encoding, so we use the input_encoder's\n",
    "\n",
    "    inputSeq = jax.numpy.array(model.input_encoder.encode(inputSeq))\n",
    "    outputSeq = jax.numpy.array(model.output_encoder.encode(outputSeq))\n",
    "\n",
    "    X.append(inputSeq)\n",
    "    Y.append(outputSeq)\n",
    "\n",
    "X = jax.numpy.array(X)\n",
    "Y = jax.numpy.array(Y)\n",
    "\n",
    "X, Y\n",
    "print(X.shape)\n",
    "\n",
    "# Remove duplicates from X, and the corresponding Y\n",
    "X, indices = np.unique(X, return_index=True, axis=0)\n",
    "Y = Y[indices]\n",
    "print(X.shape)\n",
    "\n",
    "# Split test and validation\n",
    "split = int(X.shape[0] * 0.90)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_train, Y_test = Y[:split], Y[split:]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "\n",
    "params = model.params\n",
    "hk_model = hk.transform(model.get_compiled_model)\n",
    "hk_model = hk_model.apply(params, jax.random.PRNGKey(42))\n",
    "hk_model.use_unembed_argmax = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return hk_model(x)\n",
    "\n",
    "forward = hk.without_apply_rng(hk.transform(forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding map:\n",
      "{10: 0, 20: 1, 30: 2, 40: 3, 50: 4, 'BOS': 5, 'compiler_pad': 6}\n",
      "Example input and output:\n",
      "[5 0 0 0 0 3]\n",
      "[0 0 0 0 0 3]\n",
      "Example forward pass:\n",
      "[[[2.6479832e-04 0.0000000e+00 0.0000000e+00 6.6199580e-05 0.0000000e+00]\n",
      "  [9.9993372e-01 0.0000000e+00 0.0000000e+00 4.3849981e-09 0.0000000e+00]\n",
      "  [9.9993372e-01 0.0000000e+00 0.0000000e+00 4.3849981e-09 0.0000000e+00]\n",
      "  [9.9993372e-01 0.0000000e+00 0.0000000e+00 4.3849981e-09 0.0000000e+00]\n",
      "  [9.9993372e-01 0.0000000e+00 0.0000000e+00 4.3849981e-09 0.0000000e+00]\n",
      "  [1.7539833e-08 0.0000000e+00 0.0000000e+00 9.9993372e-01 0.0000000e+00]]]\n",
      "[0 0 0 0 0 3]\n",
      "Example forward pass with model wrapper:\n",
      "['BOS', 20, 30, 40, 40, 50]\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoding map:\")\n",
    "print(model.input_encoder.encoding_map)\n",
    "\n",
    "print(\"Example input and output:\")\n",
    "print(X_train[0])\n",
    "print(Y_train[0])\n",
    "\n",
    "print(\"Example forward pass:\")\n",
    "output = forward.apply(model.params, jax.numpy.array([X_train[0]]))\n",
    "print(output.unembedded_output)\n",
    "print(output.unembedded_output.argmax(axis=-1)[0])\n",
    "\n",
    "print(\"Example forward pass with model wrapper:\")\n",
    "print(model.apply([bos, 40, 50, 20, 30, 40]).decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "@jax.jit\n",
    "def cross_entropy(logits, labels):\n",
    "  return -jnp.sum(labels * jax.nn.log_softmax(logits)) / logits.shape[0]\n",
    "\n",
    "# TODO: ignore first position and apply softmax after ignoring first position\n",
    "@jax.jit\n",
    "def loss_fn(params, x, y):\n",
    "  logits = forward.apply(params, x).unembedded_output\n",
    "  labels = jax.nn.one_hot(y, logits.shape[-1])\n",
    "  return cross_entropy(logits, labels)\n",
    "\n",
    "class TrainingState(NamedTuple):\n",
    "  params: hk.Params\n",
    "  opt_state: optax.OptState\n",
    "\n",
    "# FIXME: jax.jit is not working due to some problem with vmap\n",
    "# @jax.jit\n",
    "def update(optimiser, state: TrainingState, x, y) -> TrainingState:\n",
    "  \"\"\"Learning rule (stochastic gradient descent).\"\"\"\n",
    "  grads = jax.grad(loss_fn)(state.params, x, y)\n",
    "  updates, opt_state = optimiser.update(grads, state.opt_state)\n",
    "  params = optax.apply_updates(state.params, updates)\n",
    "  # TODO: perhaps use incremental updates with average params\n",
    "  return TrainingState(params, opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(initial_params, X, Y, n_epochs=1, batch_size=8, lr=0.0001, plot=False):\n",
    "    losses = []  # to store the loss values\n",
    "\n",
    "    optimiser = optax.adam(lr)\n",
    "    state = TrainingState(initial_params, optimiser.init(params))\n",
    "\n",
    "    for _ in tqdm.trange(n_epochs):\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            x = X[i:i + batch_size]\n",
    "            y = Y[i:i + batch_size]\n",
    "            state = update(optimiser, state, x, y)\n",
    "            \n",
    "        # Compute loss every epoch\n",
    "        if plot:\n",
    "            loss = loss_fn(state.params, X, Y)\n",
    "            losses.append(loss)\n",
    "\n",
    "    if plot:\n",
    "        # plot the loss values\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss')\n",
    "        plt.show()\n",
    "\n",
    "    return state.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(params, X, Y):\n",
    "    \"\"\"\n",
    "    Computes the accuracy (exact-match) of the model on the given data (X) and labels (Y).\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for x, y in zip(X, Y):\n",
    "        logits = forward.apply(params, jax.numpy.array([x])).unembedded_output\n",
    "        pred = jnp.argmax(logits, axis=-1)[0]\n",
    "        correct += jnp.all(pred[1:] == y[1:])\n",
    "    return correct / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct model:  1.0\n",
      "Buggy model:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct model: \", evaluate(model.params, X_test, Y_test))\n",
    "print(\"Buggy model: \", evaluate(buggy_model.params, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [13:17<00:00,  6.27it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_params = train(buggy_model.params, X_train, Y_train, n_epochs=5000, batch_size=256, lr=1e-5, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 2 2 4 0]\n",
      "[0 0 2 2 4 4]\n",
      "[0 0 2 2 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])\n",
    "print(Y_test[0])\n",
    "\n",
    "print(forward.apply(new_params, jax.numpy.array([X_test[0]])).unembedded_output.argmax(axis=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.29069766, dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(new_params, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_normal(params, mean=0.0, std=1.0):\n",
    "    return jax.tree_util.tree_map(\n",
    "        lambda p: jax.random.normal(jax.random.PRNGKey(42), p.shape) * std + mean,\n",
    "        params\n",
    "    )\n",
    "\n",
    "random_params = initialize_normal(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0., dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(random_params, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 2 2 4 0]\n",
      "[0 0 2 2 4 4]\n",
      "[1 0 2 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])\n",
    "print(Y_test[0])\n",
    "\n",
    "print(forward.apply(random_params, jax.numpy.array([X_test[0]])).unembedded_output.argmax(axis=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_epochs  batch_size  learning_rate accuracy\n",
      "0       100         256        0.00001      0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the hyper-parameter values to search\n",
    "n_epochs_values = [100]\n",
    "batch_size_values = [256]\n",
    "learning_rate_values = [1e-5]\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results = []\n",
    "\n",
    "# Perform hyper-parameter search\n",
    "for n_epochs in n_epochs_values:\n",
    "    for batch_size in batch_size_values:\n",
    "        for learning_rate in learning_rate_values:\n",
    "            # Train the model with the current hyper-parameters\n",
    "            trained_params = train(random_params, X_train, Y_train, n_epochs=n_epochs, batch_size=batch_size, lr=learning_rate)\n",
    "            \n",
    "            # Evaluate the model on the test set\n",
    "            accuracy = evaluate(trained_params, X_test, Y_test)\n",
    "            \n",
    "            # Append the results to the DataFrame\n",
    "            results.append({\"n_epochs\": n_epochs, \"batch_size\": batch_size, \"learning_rate\": learning_rate, \"accuracy\": accuracy})\n",
    "\n",
    "# Print the results\n",
    "print(pd.DataFrame(results).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 2 2 4 0]\n",
      "[0 0 2 2 4 4]\n",
      "[0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])\n",
    "print(Y_test[0])\n",
    "\n",
    "print(forward.apply(trained_params, jax.numpy.array([X_test[0]])).unembedded_output.argmax(axis=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_embed': {'embeddings': Array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],      dtype=float32)},\n",
       " 'token_embed': {'embeddings': Array([[        nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan],\n",
       "         [        nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan],\n",
       "         [        nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan],\n",
       "         [        nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan],\n",
       "         [        nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan],\n",
       "         [        nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan,\n",
       "                  nan,         nan,         nan,         nan,         nan],\n",
       "         [-0.16934101,  1.0249794 ,  1.5890766 ,  0.989513  ,  0.769241  ,\n",
       "          -1.5376883 , -0.7443877 ,  0.8018156 , -0.11315052,  0.67079186,\n",
       "           0.62283885, -1.1023544 , -0.2131008 , -0.6671398 , -2.2152178 ,\n",
       "           1.3250903 ,  1.6362431 ,  0.6746722 ,  0.3590162 , -1.0647202 ,\n",
       "          -1.4151797 ,  1.1016418 , -0.19674379, -0.39336315, -1.732082  ,\n",
       "          -1.2493681 , -0.01971422, -0.19772118, -1.3372629 , -0.2683381 ,\n",
       "           0.7578251 , -0.26835763,  0.6978463 , -0.35234237,  0.4892086 ,\n",
       "          -1.559317  , -2.0602825 ,  0.81789094, -0.42583477,  0.36295408,\n",
       "          -0.9422807 ,  0.8000539 ,  2.3604882 , -0.26209062, -0.46530747,\n",
       "           0.6096245 ,  1.3085421 , -0.41338488,  1.3395221 ,  0.3113503 ]],      dtype=float32)},\n",
       " 'transformer/layer_0/attn/key': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_0/attn/linear': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_0/attn/query': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_0/attn/value': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_0/mlp/linear_1': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_0/mlp/linear_2': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_1/attn/key': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_1/attn/linear': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_1/attn/query': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_1/attn/value': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_1/mlp/linear_1': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_1/mlp/linear_2': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_2/attn/key': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_2/attn/linear': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_2/attn/query': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_2/attn/value': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_2/mlp/linear_1': {'b': Array([ 0.90924025,  0.40489668, -0.14142953, -1.9633836 , -0.6936256 ,\n",
       "          1.0794026 , -0.10954937,  0.12105061, -0.6469501 , -1.3406506 ,\n",
       "          0.05642654,  1.7293222 , -2.1558692 , -1.6120774 , -0.21196535,\n",
       "          1.9539587 ,  0.39404425,  0.5175736 ,  0.64130646,  1.2487036 ,\n",
       "         -0.20581296, -0.80888414, -0.4648337 ,  1.5472252 , -1.195723  ],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_2/mlp/linear_2': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
