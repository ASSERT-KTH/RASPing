{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracr.rasp import rasp\n",
    "\n",
    "def make_sort_unique(vals: rasp.SOp, keys: rasp.SOp) -> rasp.SOp:\n",
    "  \"\"\"Returns vals sorted by < relation on keys.\n",
    "\n",
    "  Only supports unique keys.\n",
    "\n",
    "  Example usage:\n",
    "    sort = make_sort(rasp.tokens, rasp.tokens)\n",
    "    sort([2, 4, 3, 1])\n",
    "    >> [1, 2, 3, 4]\n",
    "\n",
    "  Args:\n",
    "    vals: Values to sort.\n",
    "    keys: Keys for sorting.\n",
    "  \"\"\"\n",
    "  smaller = rasp.Select(keys, keys, rasp.Comparison.LT).named(\"smaller\")\n",
    "  target_pos = rasp.SelectorWidth(smaller).named(\"target_pos\")\n",
    "  sel_new = rasp.Select(target_pos, rasp.indices, rasp.Comparison.EQ)\n",
    "  return rasp.Aggregate(sel_new, vals).named(\"sort\")\n",
    "\n",
    "\n",
    "def make_sort(vals: rasp.SOp, keys: rasp.SOp, *, max_seq_len: int,\n",
    "              min_key: float) -> rasp.SOp:\n",
    "  \"\"\"Returns vals sorted by < relation on keys, which don't need to be unique.\n",
    "\n",
    "  The implementation differs from the RASP paper, as it avoids using\n",
    "  compositions of selectors to break ties. Instead, it uses the arguments\n",
    "  max_seq_len and min_key to ensure the keys are unique.\n",
    "\n",
    "  Note that this approach only works for numerical keys.\n",
    "\n",
    "  Example usage:\n",
    "    sort = make_sort(rasp.tokens, rasp.tokens, 5, 1)\n",
    "    sort([2, 4, 3, 1])\n",
    "    >> [1, 2, 3, 4]\n",
    "    sort([2, 4, 1, 2])\n",
    "    >> [1, 2, 2, 4]\n",
    "\n",
    "  Args:\n",
    "    vals: Values to sort.\n",
    "    keys: Keys for sorting.\n",
    "    max_seq_len: Maximum sequence length (used to ensure keys are unique)\n",
    "    min_key: Minimum key value (used to ensure keys are unique)\n",
    "\n",
    "  Returns:\n",
    "    Output SOp of sort program.\n",
    "  \"\"\"\n",
    "  keys = rasp.SequenceMap(lambda x, i: x + min_key * i / max_seq_len, keys,\n",
    "                          rasp.indices)\n",
    "  return make_sort_unique(vals, keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerConfig(num_heads=1, num_layers=3, key_size=52, mlp_hidden_size=50, dropout_rate=0.0, activation_function=<jax._src.custom_derivatives.custom_jvp object at 0x71e8583b76b0>, layer_norm=False, causal=False)\n"
     ]
    }
   ],
   "source": [
    "from tracr.compiler import compiling\n",
    "\n",
    "sort = make_sort(rasp.tokens, rasp.tokens, max_seq_len=20, min_key=1)\n",
    "bos = \"BOS\"\n",
    "max_seq_len=5\n",
    "model = compiling.compile_rasp_to_model(\n",
    "    sort,\n",
    "    vocab={0, 1, 2, 3, 4, 5, 6, 7, 8, 9},\n",
    "    max_seq_len=max_seq_len,\n",
    "    compiler_bos=bos,\n",
    ")\n",
    "print(model.model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 6)\n",
      "(9245, 6)\n",
      "(9152, 6) (93, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "acceptedTokens = list(range(1, 10))\n",
    "maxSeqLength = max_seq_len\n",
    "size = 10000\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in range(size):\n",
    "    # TODO: implement padding for training\n",
    "    # inputLength = np.random.randint(2, maxSeqLength+1)  #Uniformly distributed between 2 and max length\n",
    "    inputLength = maxSeqLength\n",
    "\n",
    "    inputSeq = []\n",
    "    outputSeq = []\n",
    "    for t in np.random.choice(acceptedTokens, inputLength):\n",
    "        inputSeq.append(t)\n",
    "        outputSeq.append(t)\n",
    "\n",
    "    inputSeq.insert(0, bos)\n",
    "    outputSeq.sort()\n",
    "    outputSeq.insert(0, 0) # The output_encoder does has a None bos_encoding, so we use the input_encoder's\n",
    "\n",
    "    inputSeq = jax.numpy.array(model.input_encoder.encode(inputSeq))\n",
    "    outputSeq = jax.numpy.array(model.output_encoder.encode(outputSeq))\n",
    "\n",
    "    X.append(inputSeq)\n",
    "    Y.append(outputSeq)\n",
    "\n",
    "X = jax.numpy.array(X)\n",
    "Y = jax.numpy.array(Y)\n",
    "\n",
    "X, Y\n",
    "print(X.shape)\n",
    "\n",
    "# Remove duplicates from X, and the corresponding Y\n",
    "X, indices = np.unique(X, return_index=True, axis=0)\n",
    "Y = Y[indices]\n",
    "print(X.shape)\n",
    "\n",
    "# Split test and validation\n",
    "split = int(X.shape[0] * 0.99)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_train, Y_test = Y[:split], Y[split:]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "\n",
    "params = model.params\n",
    "\n",
    "hk_model = hk.transform(model.get_compiled_model)\n",
    "hk_model = hk_model.apply(params, jax.random.PRNGKey(42))\n",
    "hk_model.use_unembed_argmax = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return hk_model(x)\n",
    "\n",
    "forward = hk.transform(forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.0000000e+00 0.0000000e+00 9.6961419e-04 9.6961419e-04 9.6961419e-04\n",
      "   9.6961419e-04 9.6961419e-04 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 9.9902284e-01 9.4840647e-07 9.4840647e-07\n",
      "   9.4840647e-07 9.4840647e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 9.4840647e-07 9.9902284e-01 9.4840647e-07\n",
      "   9.4840647e-07 9.4840647e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 9.4840647e-07 9.4840647e-07 9.9902284e-01\n",
      "   9.4840647e-07 9.4840647e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 9.4840647e-07 9.4840647e-07 9.4840647e-07\n",
      "   9.9902284e-01 9.4840647e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 9.4840823e-07 9.4843352e-07 9.4840823e-07\n",
      "   9.4840823e-07 9.9902284e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00]]]\n",
      "[[2 2 3 4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "output = forward.apply(model.params, jax.random.PRNGKey(42), jax.numpy.array([[10, 4, 5, 2, 6, 3]]))\n",
    "print(output.unembedded_output)\n",
    "print(output.unembedded_output.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOS', 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply([bos, 4, 5, 2, 6, 3]).decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "jax.config.update('jax_default_matmul_precision', 'float32')\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def cross_entropy(logits, labels):\n",
    "  return -jnp.sum(labels * jax.nn.log_softmax(logits)) / logits.shape[0]\n",
    "\n",
    "# TODO: ignore first position\n",
    "@jax.jit\n",
    "def loss_fn(params, x, y):\n",
    "  logits = forward.apply(params, jax.random.PRNGKey(42), x).unembedded_output\n",
    "  labels = jax.nn.one_hot(y, logits.shape[-1])\n",
    "  return cross_entropy(logits, labels)\n",
    "\n",
    "@jax.jit\n",
    "def update(params, x, y, lr=0.0001):\n",
    "  grads = jax.grad(loss_fn)(params, x, y)\n",
    "  return jax.tree_util.tree_map(\n",
    "      lambda p, g: p - lr * g, model.params, grads\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(params, X, Y, n_epochs=1, batch_size=8, lr=0.0001, plot=False):\n",
    "    losses = []  # to store the loss values\n",
    "\n",
    "    for _ in tqdm.trange(n_epochs):\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            x = X[i:i + batch_size]\n",
    "            y = Y[i:i + batch_size]\n",
    "            params = update(params, x, y, lr)\n",
    "            \n",
    "        # Compute loss every epoch\n",
    "        if plot:\n",
    "            loss = loss_fn(params, X, Y)\n",
    "            losses.append(loss)\n",
    "\n",
    "    if plot:\n",
    "        # plot the loss values\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss')\n",
    "        plt.show()\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(params, X, Y):\n",
    "    \"\"\"\n",
    "    Computes the accuracy (exact-match) of the model on the given data (X) and labels (Y).\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for x, y in zip(X, Y):\n",
    "        logits = forward.apply(params, jax.random.PRNGKey(42), jax.numpy.array([x])).unembedded_output\n",
    "        pred = jnp.argmax(logits, axis=-1)[0]\n",
    "        correct += jnp.all(pred[1:] == y[1:])\n",
    "    return correct / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1., dtype=float64, weak_type=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model.params, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.44s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_params = train(model.params, X_train, Y_train, n_epochs=10, batch_size=128, lr=1e-5, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  9  9  2  4  2]\n",
      "[0 2 2 4 9 9]\n",
      "[[0 2 2 4 9 9]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])\n",
    "print(Y_test[0])\n",
    "\n",
    "print(forward.apply(new_params, jax.random.PRNGKey(42), jax.numpy.array([X_test[0]])).unembedded_output.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1., dtype=float64, weak_type=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(new_params, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_normal(params, mean=0.0, std=1.0):\n",
    "    return jax.tree_util.tree_map(\n",
    "        lambda p: jax.random.normal(jax.random.PRNGKey(42), p.shape) * std + mean,\n",
    "        params\n",
    "    )\n",
    "\n",
    "random_params = initialize_normal(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0., dtype=float64, weak_type=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(random_params, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  9  9  2  4  2]\n",
      "[0 2 2 4 9 9]\n",
      "[[5 7 6 7 5 7]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])\n",
    "print(Y_test[0])\n",
    "\n",
    "print(forward.apply(random_params, jax.random.PRNGKey(42), jax.numpy.array([X_test[0]])).unembedded_output.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_epochs  batch_size  learning_rate accuracy\n",
      "0         1         128          0.001      0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the hyper-parameter values to search\n",
    "n_epochs_values = [1]\n",
    "batch_size_values = [128]\n",
    "learning_rate_values = [1e-3]\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results = []\n",
    "\n",
    "# Perform hyper-parameter search\n",
    "for n_epochs in n_epochs_values:\n",
    "    for batch_size in batch_size_values:\n",
    "        for learning_rate in learning_rate_values:\n",
    "            # Train the model with the current hyper-parameters\n",
    "            trained_params = train(random_params, X_train, Y_train, n_epochs=n_epochs, batch_size=batch_size, lr=learning_rate)\n",
    "            \n",
    "            # Evaluate the model on the test set\n",
    "            accuracy = evaluate(trained_params, X_test, Y_test)\n",
    "            \n",
    "            # Append the results to the DataFrame\n",
    "            results.append({\"n_epochs\": n_epochs, \"batch_size\": batch_size, \"learning_rate\": learning_rate, \"accuracy\": accuracy})\n",
    "\n",
    "# Print the results\n",
    "print(pd.DataFrame(results).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_embed': {'embeddings': Array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan]], dtype=float64)},\n",
       " 'token_embed': {'embeddings': Array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.]], dtype=float64)},\n",
       " 'transformer/layer_0/attn/key': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_0/attn/linear': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan], dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_0/attn/query': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_0/attn/value': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_0/mlp/linear_1': {'b': Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],      dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_0/mlp/linear_2': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan], dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_1/attn/key': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_1/attn/linear': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan], dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_1/attn/query': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_1/attn/value': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_1/mlp/linear_1': {'b': Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],      dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_1/mlp/linear_2': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan], dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_2/attn/key': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_2/attn/linear': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan], dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_2/attn/query': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_2/attn/value': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_2/mlp/linear_1': {'b': Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],      dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)},\n",
       " 'transformer/layer_2/mlp/linear_2': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan], dtype=float64),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float64)}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
