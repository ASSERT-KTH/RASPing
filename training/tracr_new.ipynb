{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracr.rasp import rasp\n",
    "\n",
    "def make_sort_unique(vals: rasp.SOp, keys: rasp.SOp) -> rasp.SOp:\n",
    "  \"\"\"Returns vals sorted by < relation on keys.\n",
    "\n",
    "  Only supports unique keys.\n",
    "\n",
    "  Example usage:\n",
    "    sort = make_sort(rasp.tokens, rasp.tokens)\n",
    "    sort([2, 4, 3, 1])\n",
    "    >> [1, 2, 3, 4]\n",
    "\n",
    "  Args:\n",
    "    vals: Values to sort.\n",
    "    keys: Keys for sorting.\n",
    "  \"\"\"\n",
    "  smaller = rasp.Select(keys, keys, rasp.Comparison.LT).named(\"smaller\")\n",
    "  target_pos = rasp.SelectorWidth(smaller).named(\"target_pos\")\n",
    "  sel_new = rasp.Select(target_pos, rasp.indices, rasp.Comparison.EQ)\n",
    "  return rasp.Aggregate(sel_new, vals).named(\"sort\")\n",
    "\n",
    "\n",
    "def make_sort(vals: rasp.SOp, keys: rasp.SOp, *, max_seq_len: int,\n",
    "              min_key: float) -> rasp.SOp:\n",
    "  \"\"\"Returns vals sorted by < relation on keys, which don't need to be unique.\n",
    "\n",
    "  The implementation differs from the RASP paper, as it avoids using\n",
    "  compositions of selectors to break ties. Instead, it uses the arguments\n",
    "  max_seq_len and min_key to ensure the keys are unique.\n",
    "\n",
    "  Note that this approach only works for numerical keys.\n",
    "\n",
    "  Example usage:\n",
    "    sort = make_sort(rasp.tokens, rasp.tokens, 5, 1)\n",
    "    sort([2, 4, 3, 1])\n",
    "    >> [1, 2, 3, 4]\n",
    "    sort([2, 4, 1, 2])\n",
    "    >> [1, 2, 2, 4]\n",
    "\n",
    "  Args:\n",
    "    vals: Values to sort.\n",
    "    keys: Keys for sorting.\n",
    "    max_seq_len: Maximum sequence length (used to ensure keys are unique)\n",
    "    min_key: Minimum key value (used to ensure keys are unique)\n",
    "\n",
    "  Returns:\n",
    "    Output SOp of sort program.\n",
    "  \"\"\"\n",
    "  keys = rasp.SequenceMap(lambda x, i: x + min_key * i / max_seq_len, keys,\n",
    "                          rasp.indices)\n",
    "  return make_sort_unique(vals, keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracr.rasp import rasp\n",
    "\n",
    "def make_sort_unique_buggy(vals: rasp.SOp, keys: rasp.SOp) -> rasp.SOp:\n",
    "  \"\"\"Returns vals sorted by < relation on keys.\n",
    "\n",
    "  Only supports unique keys.\n",
    "\n",
    "  Example usage:\n",
    "    sort = make_sort(rasp.tokens, rasp.tokens)\n",
    "    sort([2, 4, 3, 1])\n",
    "    >> [1, 2, 3, 4]\n",
    "\n",
    "  Args:\n",
    "    vals: Values to sort.\n",
    "    keys: Keys for sorting.\n",
    "  \"\"\"\n",
    "  # BUG: GT instead of LT, resulting in descending order instead of ascending\n",
    "  smaller = rasp.Select(keys, keys, rasp.Comparison.GT).named(\"smaller\")\n",
    "  target_pos = rasp.SelectorWidth(smaller).named(\"target_pos\")\n",
    "  sel_new = rasp.Select(target_pos, rasp.indices, rasp.Comparison.EQ)\n",
    "  return rasp.Aggregate(sel_new, vals).named(\"sort\")\n",
    "\n",
    "\n",
    "def make_sort_buggy(vals: rasp.SOp, keys: rasp.SOp, *, max_seq_len: int,\n",
    "              min_key: float) -> rasp.SOp:\n",
    "  \"\"\"Returns vals sorted by < relation on keys, which don't need to be unique.\n",
    "\n",
    "  The implementation differs from the RASP paper, as it avoids using\n",
    "  compositions of selectors to break ties. Instead, it uses the arguments\n",
    "  max_seq_len and min_key to ensure the keys are unique.\n",
    "\n",
    "  Note that this approach only works for numerical keys.\n",
    "\n",
    "  Example usage:\n",
    "    sort = make_sort(rasp.tokens, rasp.tokens, 5, 1)\n",
    "    sort([2, 4, 3, 1])\n",
    "    >> [1, 2, 3, 4]\n",
    "    sort([2, 4, 1, 2])\n",
    "    >> [1, 2, 2, 4]\n",
    "\n",
    "  Args:\n",
    "    vals: Values to sort.\n",
    "    keys: Keys for sorting.\n",
    "    max_seq_len: Maximum sequence length (used to ensure keys are unique)\n",
    "    min_key: Minimum key value (used to ensure keys are unique)\n",
    "\n",
    "  Returns:\n",
    "    Output SOp of sort program.\n",
    "  \"\"\"\n",
    "  keys = rasp.SequenceMap(lambda x, i: x + min_key * i / max_seq_len, keys,\n",
    "                          rasp.indices)\n",
    "  return make_sort_unique_buggy(vals, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerConfig(num_heads=1, num_layers=3, key_size=27, mlp_hidden_size=25, dropout_rate=0.0, activation_function=<jax._src.custom_derivatives.custom_jvp object at 0x7344813bf2f0>, layer_norm=False, causal=False)\n",
      "TransformerConfig(num_heads=1, num_layers=3, key_size=27, mlp_hidden_size=25, dropout_rate=0.0, activation_function=<jax._src.custom_derivatives.custom_jvp object at 0x7344813bf2f0>, layer_norm=False, causal=False)\n"
     ]
    }
   ],
   "source": [
    "from tracr.compiler import compiling\n",
    "\n",
    "sort = make_sort(rasp.tokens, rasp.tokens, max_seq_len=20, min_key=1)\n",
    "bos = \"BOS\"\n",
    "max_seq_len=5\n",
    "model = compiling.compile_rasp_to_model(\n",
    "    sort,\n",
    "    vocab={10, 20, 30, 40, 50},\n",
    "    max_seq_len=max_seq_len,\n",
    "    compiler_bos=bos,\n",
    ")\n",
    "print(model.model_config)\n",
    "\n",
    "\n",
    "buggy_sort = make_sort_buggy(rasp.tokens, rasp.tokens, max_seq_len=20, min_key=1)\n",
    "bos = \"BOS\"\n",
    "max_seq_len=5\n",
    "buggy_model = compiling.compile_rasp_to_model(\n",
    "    buggy_sort,\n",
    "    vocab={10, 20, 30, 40, 50},\n",
    "    max_seq_len=max_seq_len,\n",
    "    compiler_bos=bos,\n",
    ")\n",
    "print(buggy_model.model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n",
      "(851, 6)\n",
      "(765, 6) (86, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "acceptedTokens = [10, 20, 30, 40, 50]\n",
    "maxSeqLength = max_seq_len\n",
    "size = 1000\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in range(size):\n",
    "    # TODO: implement padding for training\n",
    "    # inputLength = np.random.randint(2, maxSeqLength+1)  #Uniformly distributed between 2 and max length\n",
    "    inputLength = maxSeqLength\n",
    "\n",
    "    inputSeq = []\n",
    "    outputSeq = []\n",
    "    for t in np.random.choice(acceptedTokens, inputLength):\n",
    "        inputSeq.append(t)\n",
    "        outputSeq.append(t)\n",
    "\n",
    "    inputSeq.insert(0, bos)\n",
    "    outputSeq.sort()\n",
    "    outputSeq.insert(0, 10) # The output_encoder does has a None bos_encoding, so we use the input_encoder's\n",
    "\n",
    "    inputSeq = jax.numpy.array(model.input_encoder.encode(inputSeq))\n",
    "    outputSeq = jax.numpy.array(model.output_encoder.encode(outputSeq))\n",
    "\n",
    "    X.append(inputSeq)\n",
    "    Y.append(outputSeq)\n",
    "\n",
    "X = jax.numpy.array(X)\n",
    "Y = jax.numpy.array(Y)\n",
    "\n",
    "X, Y\n",
    "print(X.shape)\n",
    "\n",
    "# Remove duplicates from X, and the corresponding Y\n",
    "X, indices = np.unique(X, return_index=True, axis=0)\n",
    "Y = Y[indices]\n",
    "print(X.shape)\n",
    "\n",
    "# Split test and validation\n",
    "split = int(X.shape[0] * 0.90)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_train, Y_test = Y[:split], Y[split:]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "\n",
    "params = model.params\n",
    "hk_model = hk.transform(model.get_compiled_model)\n",
    "hk_model = hk_model.apply(params, jax.random.PRNGKey(42))\n",
    "hk_model.use_unembed_argmax = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return hk_model(x)\n",
    "\n",
    "forward_fun = hk.without_apply_rng(hk.transform(forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding map:\n",
      "{10: 0, 20: 1, 30: 2, 40: 3, 50: 4, 'BOS': 5, 'compiler_pad': 6}\n",
      "Example input and output:\n",
      "[5 0 0 0 0 3]\n",
      "[0 0 0 0 0 3]\n",
      "Example forward pass:\n",
      "[[[2.6479832e-04 0.0000000e+00 0.0000000e+00 6.6199580e-05 0.0000000e+00]\n",
      "  [9.9993372e-01 0.0000000e+00 0.0000000e+00 4.3849981e-09 0.0000000e+00]\n",
      "  [9.9993372e-01 0.0000000e+00 0.0000000e+00 4.3849981e-09 0.0000000e+00]\n",
      "  [9.9993372e-01 0.0000000e+00 0.0000000e+00 4.3849981e-09 0.0000000e+00]\n",
      "  [9.9993372e-01 0.0000000e+00 0.0000000e+00 4.3849981e-09 0.0000000e+00]\n",
      "  [1.7539833e-08 0.0000000e+00 0.0000000e+00 9.9993372e-01 0.0000000e+00]]]\n",
      "[0 0 0 0 0 3]\n",
      "Example forward pass with model wrapper:\n",
      "['BOS', 20, 30, 40, 40, 50]\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoding map:\")\n",
    "print(model.input_encoder.encoding_map)\n",
    "\n",
    "print(\"Example input and output:\")\n",
    "print(X_train[0])\n",
    "print(Y_train[0])\n",
    "\n",
    "print(\"Example forward pass:\")\n",
    "output = forward_fun.apply(model.params, jax.numpy.array([X_train[0]]))\n",
    "print(output.unembedded_output)\n",
    "print(output.unembedded_output.argmax(axis=-1)[0])\n",
    "\n",
    "print(\"Example forward pass with model wrapper:\")\n",
    "print(model.apply([bos, 40, 50, 20, 30, 40]).decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "jax.config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "class TrainingState(NamedTuple):\n",
    "  params: hk.Params\n",
    "  opt_state: optax.OptState\n",
    "  step: jax.Array\n",
    "  \n",
    "# TODO: define learning_rate outside optimiser function\n",
    "def optimiser() -> optax.GradientTransformation:\n",
    "  return optax.chain(\n",
    "      optax.clip_by_global_norm(1),\n",
    "      optax.adam(1e-5),\n",
    "  )\n",
    "\n",
    "def cross_entropy(logits, labels):\n",
    "  return -jnp.sum(labels * jax.nn.log_softmax(logits)) / logits.shape[0]\n",
    "\n",
    "# TODO: ignore first position and apply softmax after ignoring first position\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def loss_fn(x, y):\n",
    "  logits = forward(x).unembedded_output\n",
    "  labels = jax.nn.one_hot(y, logits.shape[-1])\n",
    "  return cross_entropy(logits, labels)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update(state: TrainingState, x, y) -> TrainingState:\n",
    "  \"\"\"Learning rule (stochastic gradient descent).\"\"\"\n",
    "  loss_and_grads_fn = jax.value_and_grad(loss_fn.apply)\n",
    "  loss, grads = loss_and_grads_fn(state.params, x, y)\n",
    "  updates, opt_state = optimiser().update(grads, state.opt_state)\n",
    "  params = optax.apply_updates(state.params, updates)\n",
    "  metrics = {\"step\": state.step, \"loss\": loss}\n",
    "  return TrainingState(params, opt_state, step=state.step+1), metrics\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def init(initial_params: hk.Params) -> TrainingState:\n",
    "  initial_opt_state = optimiser().init(initial_params)\n",
    "  return TrainingState(\n",
    "      params=initial_params,\n",
    "      opt_state=initial_opt_state,\n",
    "      step=jnp.array(0),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(initial_params, X, Y, n_epochs=1, batch_size=8, lr=0.0001, plot=False):\n",
    "    metrics = []  # to store the metrics values\n",
    "\n",
    "    state = init(initial_params)\n",
    "\n",
    "    for _ in tqdm.trange(n_epochs):\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            x = X[i:i + batch_size]\n",
    "            y = Y[i:i + batch_size]\n",
    "            state, metric = update(state, x, y)\n",
    "            \n",
    "        metrics.append(metric)\n",
    "\n",
    "    if plot:\n",
    "        # plot the loss values\n",
    "        plt.plot([m['step'] for m in metrics], [m['loss'] for m in metrics])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss')\n",
    "        plt.show()\n",
    "\n",
    "    return state.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(params, X, Y):\n",
    "    \"\"\"\n",
    "    Computes the accuracy (exact-match) of the model on the given data (X) and labels (Y).\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for x, y in zip(X, Y):\n",
    "        logits = forward_fun.apply(params, jax.numpy.array([x])).unembedded_output\n",
    "        pred = jnp.argmax(logits, axis=-1)[0]\n",
    "        correct += jnp.all(pred[1:] == y[1:])\n",
    "    return correct / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct model:  1.0\n",
      "Buggy model:  0.011627907\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct model: \", evaluate(model.params, X_test, Y_test))\n",
    "print(\"Buggy model: \", evaluate(buggy_model.params, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:58<00:00, 27.99it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_params = train(buggy_model.params, X_train, Y_train, n_epochs=5000, batch_size=256, lr=1e-5, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 2 0 3 2]\n",
      "[0 0 2 2 3 4]\n",
      "[0 0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])\n",
    "print(Y_test[0])\n",
    "\n",
    "print(forward_fun.apply(new_params, jax.numpy.array([X_test[0]])).unembedded_output.argmax(axis=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.06976745, dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(new_params, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_normal(params, mean=0.0, std=1.0):\n",
    "    return jax.tree_util.tree_map(\n",
    "        lambda p: jax.random.normal(jax.random.PRNGKey(42), p.shape) * std + mean,\n",
    "        params\n",
    "    )\n",
    "\n",
    "random_params = initialize_normal(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0., dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(random_params, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 2 0 3 2]\n",
      "[0 0 2 2 3 4]\n",
      "[0 0 2 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])\n",
    "print(Y_test[0])\n",
    "\n",
    "print(forward_fun.apply(random_params, jax.numpy.array([X_test[0]])).unembedded_output.argmax(axis=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid nan value encountered in the output of a C++-jit/pmap function. Calling the de-optimized version.\n",
      "Invalid nan value encountered in the output of a C++-jit/pmap function. Calling the de-optimized version.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FloatingPointError",
     "evalue": "invalid value (nan) encountered in jit(update). Because jax_config.debug_nans.value and/or config.jax_debug_infs is set, the de-optimized function (i.e., the function as if the `jit` decorator were removed) was called in an attempt to get a more precise error message. However, the de-optimized function did not produce invalid values during its execution. This behavior can result from `jit` optimizations causing the invalid value to be produced. It may also arise from having nan/inf constants as outputs, like `jax.jit(lambda ...: jax.numpy.nan)(...)`. \n\nIt may be possible to avoid the invalid value by removing the `jit` decorator, at the cost of losing optimizations. \n\nIf you see this error, consider opening a bug report at https://github.com/google/jax.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Repos/RASPing/.venv/lib/python3.12/site-packages/jax/_src/api.py:112\u001b[0m, in \u001b[0;36m_nan_check_posthook\u001b[0;34m(fun, args, kwargs, output)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m   \u001b[38;5;66;03m# compiled_fun can only raise in this case\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/RASPing/.venv/lib/python3.12/site-packages/jax/_src/dispatch.py:317\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 317\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/RASPing/.venv/lib/python3.12/site-packages/jax/_src/dispatch.py:322\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_nans\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 322\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_infs\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in pjit",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Repos/RASPing/.venv/lib/python3.12/site-packages/jax/_src/dispatch.py:317\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 317\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/RASPing/.venv/lib/python3.12/site-packages/jax/_src/dispatch.py:322\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_nans\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 322\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_infs\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in pjit",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Repos/RASPing/.venv/lib/python3.12/site-packages/jax/_src/profiler.py:336\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 336\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/Repos/RASPing/.venv/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:1253\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[0;32m-> 1253\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[0;32m~/Repos/RASPing/.venv/lib/python3.12/site-packages/jax/_src/dispatch.py:317\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 317\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/RASPing/.venv/lib/python3.12/site-packages/jax/_src/dispatch.py:322\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_nans\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 322\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_infs\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(update)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m batch_size_values:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m learning_rate \u001b[38;5;129;01min\u001b[39;00m learning_rate_values:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# Train the model with the current hyper-parameters\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m         trained_params \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         accuracy \u001b[38;5;241m=\u001b[39m evaluate(trained_params, X_test, Y_test)\n",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(initial_params, X, Y, n_epochs, batch_size, lr, plot)\u001b[0m\n\u001b[1;32m     11\u001b[0m         x \u001b[38;5;241m=\u001b[39m X[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m     12\u001b[0m         y \u001b[38;5;241m=\u001b[39m Y[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m---> 13\u001b[0m         state, metric \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mappend(metric)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# plot the loss values\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/RASPing/.venv/lib/python3.12/site-packages/jax/_src/api.py:118\u001b[0m, in \u001b[0;36m_nan_check_posthook\u001b[0;34m(fun, args, kwargs, output)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_nans\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_infs\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid nan value encountered in the output of a C++-jit/pmap \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction. Calling the de-optimized version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 118\u001b[0m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache_miss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Repos/RASPing/.venv/lib/python3.12/site-packages/jax/_src/pjit.py:1690\u001b[0m, in \u001b[0;36m_pjit_call_impl_python\u001b[0;34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;66;03m# If control reaches this line, we got a NaN on the output of `compiled`\u001b[39;00m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;66;03m# but not `fun.call_wrapped` on the same arguments. Let's tell the user.\u001b[39;00m\n\u001b[1;32m   1675\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1676\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax_config.debug_nans.value and/or config.jax_debug_infs is set, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1677\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mde-optimized function (i.e., the function as if the `jit` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1688\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you see this error, consider opening a bug report at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1689\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/google/jax.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1690\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(msg)\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(update). Because jax_config.debug_nans.value and/or config.jax_debug_infs is set, the de-optimized function (i.e., the function as if the `jit` decorator were removed) was called in an attempt to get a more precise error message. However, the de-optimized function did not produce invalid values during its execution. This behavior can result from `jit` optimizations causing the invalid value to be produced. It may also arise from having nan/inf constants as outputs, like `jax.jit(lambda ...: jax.numpy.nan)(...)`. \n\nIt may be possible to avoid the invalid value by removing the `jit` decorator, at the cost of losing optimizations. \n\nIf you see this error, consider opening a bug report at https://github.com/google/jax."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the hyper-parameter values to search\n",
    "n_epochs_values = [5000]\n",
    "batch_size_values = [256]\n",
    "learning_rate_values = [1e-5]\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results = []\n",
    "\n",
    "# Perform hyper-parameter search\n",
    "for n_epochs in n_epochs_values:\n",
    "    for batch_size in batch_size_values:\n",
    "        for learning_rate in learning_rate_values:\n",
    "            # Train the model with the current hyper-parameters\n",
    "            trained_params = train(random_params, X_train, Y_train, n_epochs=n_epochs, batch_size=batch_size, lr=learning_rate)\n",
    "            \n",
    "            # Evaluate the model on the test set\n",
    "            accuracy = evaluate(trained_params, X_test, Y_test)\n",
    "            \n",
    "            # Append the results to the DataFrame\n",
    "            results.append({\"n_epochs\": n_epochs, \"batch_size\": batch_size, \"learning_rate\": learning_rate, \"accuracy\": accuracy})\n",
    "\n",
    "# Print the results\n",
    "print(pd.DataFrame(results).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 2 0 1 0]\n",
      "[0 0 0 1 2 4]\n",
      "[0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])\n",
    "print(Y_test[0])\n",
    "\n",
    "print(forward_fun.apply(trained_params, jax.numpy.array([X_test[0]])).unembedded_output.argmax(axis=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_embed': {'embeddings': Array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],      dtype=float32)},\n",
       " 'token_embed': {'embeddings': Array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],      dtype=float32)},\n",
       " 'transformer/layer_0/attn/key': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_0/attn/linear': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_0/attn/query': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_0/attn/value': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_0/mlp/linear_1': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_0/mlp/linear_2': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_1/attn/key': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_1/attn/linear': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_1/attn/query': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_1/attn/value': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_1/mlp/linear_1': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_1/mlp/linear_2': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_2/attn/key': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_2/attn/linear': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_2/attn/query': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_2/attn/value': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_2/mlp/linear_1': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'transformer/layer_2/mlp/linear_2': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],      dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
